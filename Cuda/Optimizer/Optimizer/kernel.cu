#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <stdio.h>
#include <string>
#include "file_reader.h"
#include "bit_converter.h"
#include <iostream>
#include <assert.h>
#include "format_packer.h"
#include <fstream>

using namespace std;

/*
Ок, это первый метод, который я параллелю, поэтому давайте решим, как я это буду делать. Просто по индексу блока мы не можем вычислить никакие индексы,
потому что ширина-высота спрайтов неодинакова. Точнее можем, но это будет очень неэффективно. А что мы должны сделать - это каким-то образом разделить
задачи по спрайтам так же как по сайзингам и инфу о сайзингах и размерах спрайтов закэшировать. Можно сказать так - кол-во блоков = кол-во сайзингов *
кол-во спрайтов. Таким образом, поток может легко вычислить спрайт и сайзинг, которые ему обрабатывать. Если его индекс 126, а кол-во сайзингов и спрайтов
 - 22 и 40 соответственно, то его сайзинг = 126 / 40, а спрайт - 126 % 40, т.е. сайзинг четвертый, спрайт - 6й. А всего блоков 22 * 40 = 880. Че-то мало.
Хотя, это только блоки. А как внутри потоки будут узнавать о своих конкретных назначенных пикспелях? А вот как. Мы будем запускать кернел для каждого
из 880 вариантов. Поэтому для каждого потока будет очевидно кто он и где он, т.к. будет передваваться ширина и высота. Иммет ли смысл делать столько
кернелов? Для среднего размера спрайтов, скажем 128х60 вся работа целого кернела будет состоять из всего нескольких сотен тысяч операций. Целого кернела,
Карл! Это если размер блока задать 128, то будет всего 8 блоков. И это для средних размеров спрайтов. Не маловато ли работы? Может быть имеет смысл сделать
опциональное разделение кернелов по спрайтам - 1 кернел == 1 спрайт. Тогда если размер блока будет 128, блоков будет уже по крайней мере в районе сотни.
Внутри такого блока мы на вход получаем смещение спрайта, ширину и высоту, а, будучи потоком, мы можем вычислить свою позицию стандартно, т.к. ширина и
высота тут постоянные. Возможно для уменьшения дайверженс и лучшей работы с памятью стоит изолировать также разные сайзинги по блокам. Т.е. если размер
блока будет, скажем, 128, сайзинг - 8х8, а спрайт 128х48, мы запускаем кернел, передавая ему оффсет спрайта в данных, 128 и 48. На уровне блоков мы действуем
следующим образом. У нас сайзинг 8х8, поэтому рабочая ширина у нас 120, а высота - 40. Таким образом нам нужно иметь 120 х 40 = 4800 потоков. Таким образом
на этом сайзинге у нас будут работать 4800 / 128 + 1 = 38 блоков. В статической памяти у них будет храниться вся нужная им инфа - их сайзинг, их референсная
область, возможно, если памяти хватит - их карты пустоты для данного спрайта. Вообще-то памяти как-то мало везде... Может использовать 1 блок на
сайзинг-спрайт, просто очень большой? Скажем, пусть размер блока будет максимальным (1024), тогда мы сможем грузить в шаренную память спрайт, если не
целиком, то координированно частями и пройтись по нему за 5 неполных итераций. Т.е. каждый поток будет ответственнен за 4-5 отдельный областей поочередно.
Вообще система хорошая: каждый поток имеет 4-5 отдельных заданий, спрайт, загруженный в шаред мемори и можно по частям проходиться по любого размера
спрайтам. Это, конечно, все прикольно, но тогда, получается, у нас по одному блоку на кернел? А, нет, стоп. По спрайту на кернел. А в кернеле кол-во блоков
будет равно кол-ву сайзингов. Т.е. на нашем случае будет 40 кернелов, по 22 блока в каждом, и у каждого блока по 1024 потока. Кол-во потоков - 901_120.
Каждый поток будет выполнять в среднем 4.5 * 120 * 40 = 21_600 операций с, в основном, шаред памятью. Пока что с моим текущим пониманием того, как это
работает, мне это кажется отличным вариантом. И кстати, регистр и сайзинги в любом случае должны с запасом влезть в константную память.

Стоп, я что-то не додумал... Сравнивать-то мне надо будет со ВСЕМИ спрайтам. Так что память будет использоваться не только шаред, но и общая. Ну уместить всю
дату в шаред мемори не представляется возможным... Хотя, если распределить задачи по времени... Чтобы в кернеле было не 22 блока а 40х22 = 880 блоков! В
каждом по 1024 потока. После завершения всех - тупо складываем результат по сайзингам, будет 22*120*40 результата на кернел как и надо. Результатов будет
много - 22*120*40*40, более 4 миллионов. Сложить их можно будет также параллельно - завершающим складывающим кернелом. На выходе он нам сделает наши 105_600
результатов - по 4800 (120х40) результатов на спрайт для каждого из 22х сайзингов. Со всех 40 кернелов получится обратно 4 миллиона результатов, из которых
мне самой элементарной сортировкой надо будет отобрать наибольший результат. Самой элементарной - это значит запускаем блоки по 1024 потока, агрессивными
оптимизациями в 10 проходов получаем 1 наибольший, пишем в буфер, и проводим с ним ту же операцию, пока не останется 1 значение. Шикарно.

А войдмапы пускай клиенты делают - это не особо их затруднит, я думаю.

P.S. Тут только проблемы с адресацией опять же возникнут, но я уже придумал как их решить. Составляем заранее (опять же - клиентом) мапу... Хотя нет, даже
этого не нужно. Каждый блок знает заранее с какого спрайта у него референс, а с какого претендер. Так что он просто сразу знает и оба оффсета. Только вот еще
одна проблема потенциальная - т.к. мы занимаем память, скорее всего, по максимуму, на одном мультипроцессоре будет у нас жить тоько 1 блок. А работать этот
блок будет с глобал мемори. Это значит большие задержки и простой мультипроцессоров. Решение здесь - ограничить сильнее использование шаред мемори - пусть
лучше будет больше итераций. Т.е. вообще-то кол-ву памяти будет достаточно быть равным кол-ву потоков - 1024 потокам не нужно больше инфы в шаред мемори, чем
1024 + полщадь сайзинга (8х8=64 в нашем случае). Если на каждый пиксель надо будет иметь 5 байтов (4 байта цвета + 1 байт пустоты), это всего лишь около 5.3кб
памяти на блок в одно и то же время. Это значит на одном мультипроцессоре смогут сожительствовать 18 блоков. Думаю, может быть норм, особенно учитывя еще, что
в 1 процессоре одновременно могут проходить только 4 варпа, но надо смотреть. Вообще круто, что на моей карточке 96Кб общей памяти - наибольшее кол-во из
текущих. Посмотрим, что принесет 8.0 compute capability... В общем, если будет не хватать памяти, буду уменьшать размер блока и соответсвенно размер требуемой
шаред мемори на блок, таким образом увеличивая кол-во блоков на процессор.


5.12.2019
Все-таки решил заполнять карты пустот самому. Ибо для больших наборов спрайтов (а скорее всего наборы будут большими) эти карты пустот будут большого размера.
Для 100 мегапикселей например, карта пустот с 22 сайзингами будет дополнительными 300 мегабайтами информации. Есть мнение (мое), что это быстрее обсчитается
на видеокарте, чем загрузится в память... Хотя все же нет, 300 мб не так много. Это во-первых. А во-вторых вычислительные мощности - дефицитный ресурс, узкое
место. Даже если все это и обсчитается быстрее, чем прочитается с диска и загрузится, шине и диску все равно делать нефига, а за то время пока они грузят,
карта обсчитает больше действителньо нужной инфы.

P.S. Я ошибся - войдмапы занимают меньше места: не в 3 раза больше для 22 сайзингов, а всего где-то 3/4 размера. Забыл, что в каждом пикселе еще по 4 байта.


6.12.2019
Ок, я что-то не подумал. Кернелы не могут выполняться по-настоящему параллельно. Поэтому надо делать все одним кернелом. Какие следствия из этого? Да
собственно не такие уж большие, раз я решил разбивать задачи по блокам не равномерно. Просто теперь blockIdx.x будет содержать трехмерным.

Ок, с адресацией решили. Но что теперь делать с дайверженси? Пожалуй уже сейчас пора принимать меры, потому что мы уже кешируем домен, а домен разным потокам
нужен все больше и больше разный.

Итак, разберемся что же происходит у нас на уровне блока. По сути мы хотим предотвратить дайверженси разделив задачу на небольшие участки. Это значит, нам
понадобится трекать потоки, которые уже закончили работу и регулярно проводить компрессию. В принципе можно даже ввести параметр - как часто мы хотим
проводить компрессию на уровне блока и через него найти компромисс между оккупацией и производительностью.

Это все хорошо, но это все влечет за собой то, что потоки должны будут свичиться между задачами. Не слишком ли большой оверхед для возможности ограничить
дивергнецию? Да нет вроде. Тем более что не обязательно юзать шаред мемори для хранения контекстов. Хотя нет, нужно - шафл работает только на уровне ворпа.
В контексте надо будет хранить координату, на которой мы остановились. В пределах 1 спрайта это вполне может занимать 1 байт. Реже 2 байта. А можно вообще
просто присылать в кернел максимальное значение ширины/высоты и хранить побитно.

Так что если какой-то поток закончил обработку (нашел такую же область и посчитал себя повтором), то он прибавляет кол-во простаивающих потоков на 1. А во
время следующей процедуры сжатия, он возмет себе контекст соседа и продолжит его работа с момента на котором тот остановился. Ах да, еще контект должен
содержать порядковый номер области, чтобы поток знал какая область его. И все, вся инфа у него есть, пошел работать. А поток, чья работа ему досталась взял
себе например новую область, которую пока еще никто себе не брал. Или опять же - область соседа, если есть такая.

Только я вот начал сомневаться в разумности загрузки домена в шаред-память. В конце-концов как узнать какую область нам грузить? Даже в самом простом случае
это нетривиально, учитывая, что загрузить надо с запасом в сайзинг. Кто будет эти доп. данные грузить? А как быть в случае с пропусками? При большом разбросе
есть вероятность, что нам понадобится весь кандидатский спрайт. Думаю, надо отказаться от идеи кеширования домена в шаред-мемори. Может это и к лучшему.
Во-первых будет большая оккупация. Во-вторых можно будет не особо экономить на других вещах, скажем, не хранить данные контекста побитово, а тупо каждому
выделить по 2 байта с барского плеча и пусть ни в чем себе не отказывают. Так 1 блок будет занимать 6Кб. Вообще-то все равно дофига, оккупация будет
слабенькой. Лучше уже хранить побитово. Да уж, если контекст столько занимает, может и все равно пришлось бы отказаться от кеша, т.к. лучше обойтись без кеша,
чем иметь большую дивергенцию. Получается, что для средних заданий, скажем изображения до 64х64 и до 256 спрайтов у нас контекст одного потока займет 20
битов, а это оккупация 38 блоков на см! Большие же задания приведут к меньшей оккупации, но, т.к. там сами блоки будут выполняться дольше, думаю, это в
какой-то мере скомпенсирует меньшее кол-во блоков на см.

А стоит ли вообще заморачиваться с контекстами? Вообще-то чем больше размеры спрайта тем более стоит и чем меньше тем менее. А раз мы ориентируемся на
большие спрайты, то, видимо, стоит. Допустим, у нас задание, состоящее из спрайтов 256х192. Это (256 - 8) * (192 - 8) * 64 = 2_920_448 операций для каждого
потока. Выигрыш может быть значительным.


7.12.19
Ок, оказалось, что лучше загружать в см не наш спрайт а спрайт кандидата, т.к. наш спрайт всегда разный у каждого блока и на карте более оптимизирована для
массовых запросов глобальная память. Запрос же одного и того же значения разными потоками, который гораздо чаще будет осуществляться именно к спрайту
кандидата, более оптимизирован из шаред мемори - там по сути идет 1 запрос и остальным потокам это значение раздается мультикастом. Я подумываю сделать такую
оптимизацию - загружать в шаред мемори не всю инфу, а лишь по одному каналу. Т.к. нас интересуют совпадения, этой инфы хватит в 255 из 256 случаев, т.е. мы
таким образом уменьшаем пол-во запросов к глобал мемори до 1/256 случая.

Таким образом использование шаред мемори увеличивается на 1024 байта, если мы кешируем только кандидатский спрайт и до 2 кб, если еще и свой. Хотя...
Вообще-то да, там ведь из-за ужимания будет та же проблема с невозможностью предсказать наличие в шаред-мемори ни одного пикселя кроме своего. Да, ок.
Получается, единственное что мы имеем возможность кешировать с таким подходом - это вспомогательные флаги, скажем, карты пустот, или может быть придумать
еще какой-то признак, типа r >= 127, сразу уменьшая кол-во загрузок из глобальной памяти вдвое. Для большого спрайта, размером, скажем, 256х256, такая маска
будет весить 8 кб, что вполне нормально.

Можно было бы конечно разделить спрайты на дальнейшие куски, таким образом, чтобы стало возможным загрузить всю инфу этого куска в шаред-память полностью и
это не сильно сказалось бы на оккупанси. Давайте посчитаем - допустим приемлемое кол-во занимаемой памяти для блока - 16 кб, это 6 резидентов на процессоре.
Все равно мало, но допустим. Тогда мы должны будем ограничиться куском в 4096 пикселей, это, например, картинка 64х64. И это только для одного спрайта.
Загрузив два спрайта, пикселей будет всего 2048, или куски примерно 64х32. Получается, каждый поток сможет проверить лишь 2048 областей. А учитывая
использование войдмапов и того меньше. В общем, не факт, что оно того стоит, непосредственная работа может быть сделается быстрее, чем загрузится такое
кол-во памяти, т.е. налицо будет неравномерное распределение нагрузки по ресурсам видеокарты. Или, наоборот более равномерное? Вроде бы пока инфа грузится
процессор может выполнять новые ворпы. Но в случае с 16 кб, если всего 5 альтернативных блоков по 32 ворпа, т.е. 160 альтернативных ворпов. Мне кажется, если
уж делать нагружать память по полной, нужно обеспечить высокую оккупацию. Если сделать так, что блок будет работать с 4 кб инфы от своего и кандидата, то
это по 8 кб на блок и 12 резидентов, или 384 альтернативных ворпа.

Так, так, нет, отмена. Максимальное кол-во варпов-резидентов на см составляет 64 для моей архитектуры, значит, в целом, для блока шириной 1024, оптимальное
потребление шаред памяти - 48 кб. Тогда на см будет ровно два блока-резидента и вся память будет зайдествована. Что это значит? Это значит что мы не можем
обеспечить высокую оккупацию за счет увеличения кол-ва блоков или ворпов (<=64) или потоков (<=2048) в принципе. Таким образом нам остается использовать эти
48 кб на блок максимально эффективно, в том числе для уменьшения дайверженси и увеличения оккупации своими силами. А это как раз, что достигается тем, о чем
я рассуждал в позапрошлом абзаце. Но тогда я не знал про это ограничение. Теперь нам остается только решить на что потратить эти 48 кб.

Предположим, что средний размер спрайта у нас будет 256х256.
Тогда одна битовая маска у нас будет занимать 8кб. Мы можем взять, например:
1 карту пустоты полную.
4 битовых карты для 4х каналов.
Оставшиеся 8 кб - это 8 байтов информации на поток. Пока что из них я вижу 6 уйдет на контекст - 2 шорта для описания своей области и кандидатской и по 1
байту на описание текущей точки остановки. Вообще, я могу выделить и по полтора байта, таким образом сразу предупредив поддержку спрайтов до 4096х4096. И
таким образом у меня останется всего 1 неиспользованный байт.


8.12.2019
Ок, хранить по 1.5 байта на контекст, пожалуй, не буду, потому что я не уверен, как это будет записываться, думаю поведение при записи может быть undefined.
Так что выделю сразу 2 байта.

А вообще да, мы конечно молодцы, выделили 2 байта, типа поддерживаем спрайты до 65536х65536, а на деле все наши рассчеты были для спрайта размером 256х256.
Вообще с таким подходом максимум, что может потянуть 1 см - 512х256, тогда 1 блок займет всю шаред память под завязку. Поэтому мы должны иметь это в виду. В
будущем, возможно, надо будет сделать варианты кернелов для больших текстур - с некоторыми отключенными флагами например. В принципе, если оставлять размер
контекста, каким мы его видим сейчас, 8 кб на блок, то максимальный поддерживаемый размер спрайта, который может использовать хотя бы 1 вспомогательную мапу
(саму полезную, пускай будет войдмапу) - это 1024х704 - (96Кб - 8Кб контекста) * 1024 * 8 = 720_896 бит информации доступной для записи какого-нибудь флага,
т.е. меньше 1мегапикселя, довольно скромно. Т.е. это граничный вариант, при котором возможно кеширование хоть чего-нибудь, дальнейшее увеличение размера
приведет к отсутствию хоть какого-то кеширования и существенному замедлению производительности. Хотя можно все еще кешировать, просто неполную информацию -
часть информации будет с кешем, часть без кеша, тоже вариант, хоть какая-то доля кеширования все же будет.

Так ок, еще одна засада, мы сейчас раздали шорты областям, а ведь если они будут шортами, то они смогут обозначить себя лишь на области 256х256. Так стоп. А
нафига мне хранить области и еще дополнительно координаты? Ведь это одно и то же! В общем, мне нужно всего лишь по 4 байта для своей и кандидатской области.
При этом обе можно хранить в виде координат. Хотя нет, попробую сначала хранить их порядковыми номерами, потом посмотрю, что удобнее.

Так, так, так, еще одна засада - я рассчитал все значения для одного спрайта. Для двух, потребуется в 2 раза больше памяти. Этого мы себе позволить не можем.
Вообще вариантов с использованием всех 96кб одним блоком не может быть, потому что половина см будет простаивать. Таким образом нам надо по-другому
распределить выделенные 48 кб.

8 кб на контекст.
16 кб на войдмапы
и остается всего 24 кб. Мы можем взять еще по одному флагу, скажем r-флаг.
И у нас останется неиспользованными еще 8 кб. Может быть есть смысл их оставить пока что неиспользованными. Т.к. эффективно использовать именно 8 кб я сейчас
не могу. А в будущем, возможно они понадобятся.

Ок, новая проблема. Динамически мы можем инициализировать лишь 1 значение. Следовательно надо будет сделать 1 общий массив, содержащий все флаги и кеши и
потом из него сделать нужные нам подмассивы. Структура этого общего массива должна быть такой: ourR + candidateR + ourVoid...

Придумал. Нам совсем не обязательно кашировать оба войд-массива. То, что мы - войд, мы можем посчитать сами довольно эффективно, для этого не нужен кеш, т.к.
считать придется всего 1 раз. И получается что у нас остается еще 16Кб, которые мы можем потратить на еще 1 флаг-канал.

Итак, структура общего массива: ourR + candidateR + ourG + candidateG + candidateVoid: 8 кб + 8 кб + 8 кб + 8 кб + 8 кб = 40 кб. Это мы пока что не
рассматриваем другие варианты кроме спрайтов 256х256. Далее можно будет не только сделать варианты для большего размера текстур с меньшими оптимизациями, но и
для меньшего размера текстур с большими оптимизациями.

Хм, кстати... Если я заранее знаю размеры структур, то зачем мне динамическая инициализация? Я могу просто проинициализировать массивы по-максимому для
данного типоразмера. Просто если спрайты окажутся меньше, этот массив окажется недозаполненным. Но я все равно не смогу эту недозаполненную память
использовать, потому что я тут должен ориентироваться на максимальный размер. Ок, делаем так тогда - это облегчит инициализацию.

Ок, записываем мы флаги в таком порядке. Для каждого спрайта записываем поочередно все пиксели. Для каждого потока нам надо будет определить сперва смещение
спрайта. В принципе мы можем использовать регистр. Просто делить значение на 4. Я проверил - нет нужды делать на 4, т.к. в регистре записан сдвиг по каналам,
т.е. по байтам.

Так, нет, стоп, нельзя просто так взять сдвиг из регистра, т.к. флаги мы записываем побитно, поэтому эти оффсеты не будут точны. Так что надо еще сделать
битовый регистр.

Ок, это самая муторная часть, но потом уже будет полегче и поинтереснее...

9.12.2019
Ок, кажись я кое-чего не учел. А именно - отступы сайзингов. С кешированием все понятно - мы кешируем все флаги данного спрайта без исключения. А вот с
войдмапами совсем другая история. Там войдмапы имеют другую размерность нежели спрайты, поэтому их будет меньше, но это не столь важно. Непонятно откуда брать
размер данных войдмапа каждого спрайта. Мы их тупо не присылаем. Надо прислать, опять в регистр, наверно. Так, нет, стоп. А откуда ж регистру знать об этом,
если он вообще не учитывает сайзинги? Блин, надо тогда самому вычислять что ли? Не, это нереально. Надо отдельную структуру под это?

10.12.2019
Блин, пипец, конечно, сколько разных структур данных, очень трудно это все сразу в голове держать.

Ок, нужно расписать раз и навсегда правильный вариант записи битовых оффсетов - битовые оффсеты всегда записываются по своим группам и с округлением до
байтов. У меня и войдмапы были неправильно записаны, и судя по всему еще и флаги щас надо будет переделывать.

Ок, похоже я еще не начал, а уже приближаюсь к максимально возможному числу регистров процессора на поток. На самом деле число регистров на см - всего 64к. В
рассчете на поток при наших плановых 2048 потоках это всего 31.25 потоков. Пипец какой-то. Т.е. это не только мегасложно удержать все в голове, но еще и надо
при этом стараться переиспорльзовать переменные, т.е. они скорее всего будут с малоговорящими названиями. Круто.

Ок, у меня уже только в качестве аргументов функции используются 18 регистров. И где-то на 30й-31й переменной оно отваливается. И это только то, что вижу я.
Там еще возможно при разворачивании выражений добавляется, скорее всего до максимальных 62х регистров на поток. Короче надо врубить режим максимальной
экономии.

11.12.2019
Давайте посчитаем как нам уложиться в 30 регистров.

Ну, во-первых, надо избавляться от такой раскоши, как хранение ссылок на однородные части массивов отдельно. r, g, b и a идут лесом, вместо них rgba.
sizingsCount и spritesCount непонятно что вообще делают в аргументах - им место в контантах.
В принципе вообще все, что не массивы может идти в константы. Хотя, собственно у нас таких только 2... ну ладно.
Хранение отдельных составляющих blockIdx, естественно, тоже не имеет смысла.
Отдельные каналы флагов тоже уходят.
На самом деле не обязательно сейчас прямо жестко оптимизировать. Достаточно, чтобы хотя бы все заработало и протестировать. А потом можно будет уже жестко оптимизировать.
Не вижу причин voidLengths не кинуть в константы. Они маленькие и запрашиваются потоками не параллельно. Ну хотя как немного? Для такого небольшого набора как 40 спрайтов и 22 сайзинга - это 4 * 40 * 22 = 3520 байт. Константной
памяти у нас всего 64 кб. Допустим, 4 кб мы займем единичными константами. Оставшихся 60Кб хватит на то, чтобы разместить оффсеты для 2792 спрайтов при 22х сайзингах. Ну, вполне реальная цифра для большого проекта. Для бОльших
циферь, думаю, можно будет что-нибудь придумать.
Сайзинги тоже идут в константы.
Думаю, весь регистр тоже туда идет. Это для условных 2000 спрайтов 24 кб


12.12.2019
Ок, оказалось, что нельзя делать константы из массивов, не зная их длину заранее. Для каких-то данных это не проблема, для других это решаемо с некоторыми оговорками, для третьих это нелья делать вообще.

А вот еще один прием. Нам ведь не нужны особо большие константы. Можно заблокировать кол-во сайзингов, скажем, на 22, и все оставшееся место распределить пропорционально этому кол-ву сайзигнов. Тогда и
выяснится максимальное кол-во спрайтов. Точнее даже не спрайтов, а в целом пикселей.

Итак, у нас всего пока что занято 12 байтов единичными значениями, все остальное - массивы. Остальное состоит из следующего:
22 * (sizeof(short) + 2) - все сайзинги. = 22*4 = 88
spritesCount * (sizeof(int) + sizeof(int) + sizeof(short) + sizeof(short)) - битовые и байтовые сдвиги спрайтов (int), а также их ширина и высота (short) =  12 * spritesCount
spritesCount * 22 * sizeof(int) - сдвиги карты пустот. = 88 * spritesCount
Итого, как ни странно уравнение для неизвестного получилось 100 * spritesCount = 64кб - 100б. Решив его мы получаем spritesCount = 654.36. Мда, маловато. Наверное придется исключать карты пустот. Тогда
spritesCount получится равным 5453. Уже более-менее. На самом деле можно сделать отдельные версии кернела для разного кол-ва спрайтов, с теми или иными ограничениями и трейдофами.


15.12.2019
Ок, наконец преодолел загрузку. Надо сказать, я весьма удовлетворен - почуствовал себя, как будто вернулся на 3 года назад, во времена, когда я сталкивался с новыми трудностями каждый день. Как-то уже отвык
от этого. Многое узнал, многому научился. Поехали дальше.

Теперь, когда все нужные мне данные на месте, надо начать их использовать. Я уже в принципе расписывал алгоритм, но это было до всей возни с памятью, так что лучше распишу еще раз. Каждый блок ответственен
за 1 спрайто-сайзинг. Это означает что 1024 потока - это все, что есть у блока для того, чтобы выдать инфу за весь спрайто-сайзинг. Так как у одгого спрайтосайзинга может быть гораздо больше, чем 1024
пикселя, потоки у нас сложные - работают с контекстами - могут подбирать контексты у других, создавать новые, отправлять их на свалку. А теперь подробнее.

1) В начале наши 1024 потока разбирают первые 1024 пикселя спрайто-размера и записывают в контекст соответствующую инфу - номер пикселя и текущий номер проверяемого пикселя кандидата (в первую итерацию,
везде равный 0 (хз, может стоит как-то это дело распидорасить (хотя войдмапы и флаги и так загружены в константную память и не требуют распидорашивания))).

2) Далее каждый поток проверяет последовательно области на спрайте-кандидате (которых у нашего блока ровно 1).
	а) Если область войд - continue
	б) Если область не совпадает - идем на следующую
	в) Если область совпадает:
		I) Если область находится до нас - мы повтор. В этом случае помечаем в контексте себя как повтор, а в счетчик повторов блока записываем +1 и дальше ничего не делаем.
		II) Если область находится после нас или если она - мы, записываем себе +1 совпадение в счетчик совпадений.

3) После определенного кол-ва итераций мы проверяем счетчик повторов. Если он больше 32 - значит освободился целый варп и мы можем ужать наши задачи для повышения.... Так... так-так-так. Стоп. А нафига нам
ужимать вообще? Ну ужмем мы, допустим даже мы занимали 32 варпа, а стали занимать 1. Мы все равно не сможем использовать оставшиеся 31 варп, т.к. память и регистры все еще забиты под завязку, там максимум
рассчитано на два блока на см. Ни больше ни меньше. Мда. А хотя.... Если например 1024 потока наши должны будут выполнить работу для в 5 раз большего кол-ва пикселей, ужатие может иметь смысл, т.к. память
вся уже и так нужная. Я думаю, до конца вполне может дойти половина варпов, а уж 1/5 и подавно. Так что если спрайты не совсем маленькие, хотя бы 64х48, это уже будет очень круто. А уж большие спрайты, типа
256х256 - там вообще 64 пикселя на поток заданий. Без ужатия никак. Так вот. Проверяем счетчик варпов. Если их больше 32 - проводим ужимание в максимум 32 прохода - это если в каждом из 32 варпов остался 1
актуальный пиксель. А так проходов должно быть больше. Каждый первый поток варпа ужимает свой варп. Затем каждый первый двух варпов и т.д. Или можно по-другому. Можно записывать номера пикселей, с которыми
закончили и затем просто как-то пойнтер сдвигать на 1. Для этого нужен пойнтер. Что если массив контекстов будет содержать пойнтеры на память откуда надо брать инфу, и этот массив будет менеджиться
параллельным кернелом? Что-то я не помню, можно ли так сделать. Посмотрел. Да, можно. Будет параллельный стрим, исключительно для мониторинга области контекстов и ужимающий их. Тогда выходит что эти счетчики
и массив контекстов должны быть в глобал мемори. Ок, норм тема. Не терпится запилить.

4) После того как все подсчеты завершены у нас есть на выходе - массив со счетами для каждой области данного спрайто-размера-спрайта. Теперь мы должны просуммировать все эти результаты с результатами других
блоков, работавших с тем же спрайто-размером, но с другими спрайтами-кандидатами. При этом, у каких-то блоков может оказаться, что область повтор а у других нет. Если у одной повтор - у всех повтор. Эту тему кстати
тоже можно мониторить параллельным стримом, чтобы не делать лишнюю работу.

5) На этом этапе у нас есть на входе все счеты всех областей всех размеров. Надо теперь найти наибольший из этих счетов. Ну это тривиально.

6) Вычитаем со всех спрайтов область-"победитель" и записываем все ее соответствующие области в структуру-результат, еще обновляем войдмапы соответствующими новыми войдами. GoTo 1.

На самом деле этот параллельный стрим - прикольная тема, он может взять на себя всю заботу о контекстах, а это значит? что он может даже самое первое распределение на каждой итерации подготавливать таким
образом, чтобы туда не попали пустые области. Красота. Но сложно, конечно. Будет чудесно, если к февралю закончу.

А с другой стороны первую итерацию можно делать и без ужимания. Так и быстрее получится выпустить и легче потом тестировать, наверное. Для простоты можно еще и войды пока не обновлять. В общем, фигарим МВП.


16.12.2019
А зачем мне проверять спрайты, стоящие до моего спрайта? Любые совпадения, найденные там будут засчитаны одинаково - как повторы. Поэтому можно просто в самом начале, еще до кеширования проверить и записать
везде нули в этом случае, чтобы они не влияли на конечный результат. Хотя... А как мы поймем, что этот спрайт повтор, если не будем проверять такие случаи? А нам обязателньо знать что спрайт - повтор? Я
думаю, нет. Потому что если он повтор, худшее что может быть - это ничья по счету с другой такой же областью, а ничья означает одинаковый результат во всех отношениях, поэтому какую из этих областей взять -
неважно. А если у повтора будет меньший счет он просто не выиграет. А так мы просто уменьшим кол-во работы почти в 2 раза. Кроме того сама концепция повтора никуда не девается - если встретили повтор,
перестаем себя обсчитывать. Так что минусов тут нет.

Еще, т.к. мы пока делаем МВП и без ужатия, то нам не нужна такая штука как контекст, так что временно убираем его.

Ок, еще одна проблема - нет гарантий, что в ситуации гонки у нас запишутся все нужные данные. Поэтому нам нежелательна ситуация, когда одновременно выполняются блоки одного и того же
спрайт-сайза. Лучше будет если одновременно выполняются блоки разных спрайт-сайзов. Но у нас нет инструментов для гарантирования этого. Хм... проблема...

Ок, есть маза сделать последовательный запуск кернелов так чтобы каждый кернел работал только с одни спрайто-размеро-спрайтом. Это гарантирует синхронизацию между блоками. А чтобы не использовать
цпу, будем делать это прямо с девайса. Прикольно. Это на самом деле хорошо подходит, потому что константы и глобал мемори не нужно перезагружать. Правда надо будет перезагружать шаред-мемори...
Правда в шаред мемори у нас в основном кандидатские данные, которые и так перезагружаться должны каждую итерацию, но есть ведь и данные нашего спрайта... Ну тут я не знаю, что делать. Можно,
конечно, убрать наши данные и загружать больше кандидатских. Хотя нет, смысла в этом 0. Лол. Вообще-то они и раньше загружались постоянно - каждый блок грузит эти данные себе и они там
повторяются. Так что все норм в этом плане. Вообще потоки памяти будут, конечно, адовые. Там судя по всему будет память, занимаемая спрайтами, в квадрате, т.к. все сравниваются со всеми. 3000
спрайтов должны сравниться каждый с каждым, поэтому будет всего загружено 9 миллионов а не 3 тысячи. Чето это как-то не айс. Нет, пропускная способность памяти у видюхи, конечно на завить - там
вроде сотник гигабит/сек, т.е. теоретически 2 терабайта данных пропустить можно за несколько минут. Может это и ок...

В любом слачае сейчас надо сделать контролирующий кернел для междублочной синхронизаци, т.к. без этого мы не все контролируем.


17.12.2019
Поразбирался слегка в этом динамическом параллелизме и, кажись, это не обязательно, можно сделать по-другому, проще, и по результату даже быстрее. Кол-во блоков будет равно кол-ву спрайто-сайзов, т.е. в
принципе немало, даже для нашего тест-кейса (40 х 22 = 880 блоков), а обычные реальные задачи будут занимать десятки, если не сотни, тысяч блоков, таким образом обеспечивая хорошую оккупацию. Так вот. Каждый
блок обрабатывает всех кандидатов последовательно. Это по сути то же самое, как если бы мы сделали с кернелами - там тоже не было бы параллелизма в этом плане. Я как-то не нашел решения, чтобы обеспечить
параллелизм обсчетов спрайто-размеро-спрайтов, но при этом синхронизировать запись их результатов. Хотя... Да нет, никак. Может как-то и можно, но оставим эти попытки на будущее - уж слишком геморройные
пути я вижу. Пока что просто последовательный обсчет всех кандидатов в одном и том же блоке будет и быстрее (из-за того, что не надо каждый раз снова кешировать свой спрайт в шаред-мемори и менеджить
переходы из кернела в кернел) и легче технически.


22.12.2019
Ок, динамический параллелизм все же нужен - во-первых тупо не хватает регистров. Даже на подсчет еле-еле наскреб. Ну и главное - иначе невозможно синхронизироваться между блоками. Ну... разве что через цпу
все делать, но это не вариант. Походу я после переделки проекта потерял какой-то лог, где рассчитывал максимальные размеры констант. А нет, от 12.12 запись это. Пипец давно чето. Ок, походу не хватает
констант мемори для компайлера. Надо чуток освободить... сделаем макс. кол-во спрайтов равным 650 вместо 654.

Вот тут если что ответ че делать чтобы использовать динамический параллелизм: https://viralfsharp.com/2014/08/17/compiling-cuda-projects-with-dynamic-parallelism-vs-201213/

Ок, с этим разобрались. Сейчас надо сделать первую версию с динамическим параллелизмом. По идее мне надо иметь общее кол-во непрозрачных пикселей и в главном кернеле сделать цикл while, и в нем пока есть
непрозрачные пиксели делать следующие 3 вещи: считать очки, выделить из них наиболшие, область с наибольшим подсчитанным счетом убирать со всех мап. В этом собственно будет заключаться вся работа. Но третий
пункт слишком массивная задача, пока что хватит реализовать 1 неполный проход цикла - подсчет и поиск наибольшего значения и сравнить его с результатом цпу.

Ок, пришла пора расписать подробно алгоритм поиска наибольшего результата. Как я это сделаю... Грубо говоря, на входе у нас массив интов длиной во всех рабочих пикселей. В каждом элементе массива у нас счет
данной области. Короче если размер блока у нас как и прежде 1024, то количество блоков должно быть размер массива / 1024. На самом деле тоже непонятно как синхронизироваться между блоками. А, ну да,
рекурсивно дергать кернел же. Ок. Значит дергаем кернел пока не останется меньше или равно 1024 кандидатов и там уже доделываем все в 1 кернеле.

Ок, с формой понятно. Что с содержанием? Чтобы мне не просто упорядочить некие значения, а привязать их к областям, мне надо хранить еще и индексы областей вместе со значениями. Для первой итерации индекс
можно будет понять из номера блока и номера потока. А дальше надо будет их как-то хранить. Чтобы не делать условия, надо как-то, я думаю, вне рекурсии подготовить этот массив индексов. Мне надо что-нибудь
грузить в шаред память? Да, наверное, нет. В пределах 1 варпа обмен данными будет происходить мультикастом, а т.к. обмениваться данными между варпами можно лишь довольно медленно, а между блоками вообще
непонятно как обмениваться, то сразу после вычисления победителя в пределах 1 варпа будет происходить перевызов кернела. Тааак... А как я собрался рекурсией вызывать кернел если я не могу гарантировать
что другие блоки не закончили работать?

А есть смысл использовать 1 блок? Да нет. Кол-во результатов будет огромным. Надо просто на уровне блока выявлять победителей, как-то дожидаться окончания работы всех блоков и... Я что-то единственный
приемлемый вариант вижу - запускать кернелы последовательно и заполнять вспомогательные промежуточные массивы с промежуточными победителями.


2.1.2020
Ок, сделал нахождение победителя, проверил на цпу, немножко пооптимизировал, чтобы запускалось как надо. Теперь надо сделать удаление области со спрайта и запись удаленных областей в какую-нибудь структуру.
И после можно будет перезапускать цикл до победного. Хм, а как же нам динамически записать все области? Полюбому нужен буффер. Только вот размер будет полюбому неопределенным заранее.

Думаю, надо сделать такой формат. Сначала идет номер спрайта, затем координаты области, затем ширина и высота. Далее идут структуры вида: номер спрайта - координаты. А вообще-то у меня же вроде это уже
где-то выполнено...

Позже...
Ок, это уже где-то выполнено, но сначала надо хотя бы в произвольном формате все это записать.

Ок, для обозначения области нужно 5 интов - index, x, y, width, height
Дальше на каждую область надо сохранять 3 инта - index, x, y

Ок, нужен общий буффер для записей вида (index, x, y, width, height) -> coincidents count -> (index, x, y)[]
И нужен какой-то буффер для временных записей. Хм.... хм, хм, хм. А может сделать матрицу, размером с дату, и ее хватит на любую конфигурацию областей, даже на "все области по 1 пикселю"-конфигурацию? В
каждой entry матрицы будем хранить просто индекс области из атласа. Ширину-высоту хранить не надо - хранится в атласе, смещение хранить не надо - хранится прямо в координатах матрицы, таким образом нам
нужна область памяти размером с rgbaData'у * int, и еще область для хранения атласа. А для хранения атласа нам потенциально нужна область размерм с rgbaData'у х3. Посчитал - для 65к спрайтов по 255х255
понадобится 32 гб оперативной памяти. Вообще-то такую инфу можно и свопать. Тем более, что это максимум, что может нам понадобиться. Надо как-то сделать так, чтобы динамически запрашивать память, иначе это
пипец. Вообще это кол-во спрайтов такого размера означает 4096 мегапикселей информации. Или 256 4к-текстур. Это сразу месячная зп если что, так что может и ладно, пусть свопается. А не будет свопаться
только где-то 21к текстур 256х256.

Ок тогда значит имеем два буффера - один для атласа, другой для координат. Выделяем на них место сразу. В буффер атласа записываем области по порядку значит. В координаты записываем их индекс. После
окончания ужмем это все, конечно.


13.1.2020
Ок, я отдохнул пару-тройку дней, и заодно подумал над одним очень странным багом в расслабленном режиме. И, блин, правильно сделал, потому что иначе хрен бы я нашел проблему если бы заставлял себя. Тут дело
в том, что у нас многие области перекрываются и, т.к. стирание происходит по большей части параллельно, каждый поток думает, что его область еще не стерта, хотя в реальности некоторые из них ошибаются.

Решение мне не особо нравится, но другого я пока не могу придумать. Надо выделить каждому потоку по спрайту. С другой стороны, при кол-ве спрайтов в районе нескольких тысяч оккупация будет практически
идеальной. Не оптимально будет только в случае мелких наборов. Но просто иначе никак. Любое деление на части меньше спрайта будет рвать граф пикселей, а вся логика этого алгоритма построена на связанности
этого графа. Разве что разделить граф, но потом еще пройтись дополнительно по району границ. Но это слишком сложно, оставим для неближайшего будушего. !!!ДАЛЬНЕЕ БУДУЩЕЕ!!! (буду помечать так, чтобы потом
было легко найти).

...чуть позже
Так, ок, еще одна важная деталь, которая вообще не очевидна. Нам надо не только запрещать стирать исходную область, но и "повреждать" ее! Т.е. такое вполне может быть, что другая область находится внутри
исходиной и стирая ее мы повредим исходную и не сможем больше валидно проверять. Вот блин!

...еще попозже
Ок, починил конечно, но все равно в самом конце несовпадение - вместо двух областей по 1 пикселю у меня 1 область 2х2. Общая сумма у этих двух вариантов одинаковая, поэтому я даже дальше не стал
разбираться, почему не совпадает - упорядочивание я на шарповой стороне не контролирую. Поэтому, думаю, можно принять это за успех, а исправить это потом с помобщью более совершенного подсчета очков -
сейчас, конечно, там наиболее простой вариант, в котором многое не учитывается.

Следующий этап - надо сделать отсылаемый обратно клиенту пакет.


15.2.2020
Ок, прошло больше месяца, и первая итерация завершена. Блять, ну надо же, не может быть... Короче пора заниматься оптимизацией и вообще вспоминать все что я собирался сделать когда делал алгоритм. Первое -
используем войдмапы. В VoidOffsets у нас константы-оффсеты войд-бит для... точно, voids. Там у нас хранится в данный момент 650 * 22 * спрайто-зайзового размера битовых войдмап.


16.2.2020
Ок, я нифига не помню, и\или не понимаю. Надо начать с того, что еще раз проверить что мы правильно читаем войдмапы.


18.2.2020
Ок, все вроде бы наконец-то более-менее хорошо. Процесс наладился, как работает все вспомнил, некоторые очень странные глюки поняты и исправлены. Удалось сократить вермя выполнения более чем вдвое с помощью
самых элементарных оптимизаций - с 723 секунд до 354:

723 -> 565 (voidmaps) -> 594 (flags loading) -> flags utilizing (r&g) (635) -> alpha minor optimization (563) -> flags loading and utilizing off (447 nice...) -> self void testing (354!!)

Теперь, я помню, была еще одна оптимизация, которую я отложил. Что-то не совсем тривиальное, про то, что нет смысла проверять какие-то области... Ах да. Что нет смысла проверять вообще что-либо до нас. Так ли
это? Если область до нас... Да, вон от 16.12.2019 объясняется. Но там вроде ошибка. Если мы будем игнорить все до нашего спрайта, мы никогда не узнаем о том, что хоть кто-то повтор, потому что чтобы это узнать,
надо проверить спрайты до нас. Но тут есть важное обстоятельство. Смысл проверки на повтор - уменьшение кол-ва работы. Т.е. если мы повтор - перестаем проходиться по всем спрайтам. Но если наш спрайт находится
где-то во второй половине бд, нам надо будет пройти половину бд только чтобы понять что мы не повтор и дальше уже допройти бд. Что мы можем в этом случае сделать? Если спрайт находится в первой половине - он
может узнать что он повтор рано и отключиться. Если во второй - поздно, поэтому выигрыш маленький от проверки и выгоднее заигнорить все до нас и начать с нас, правильно? Если мы повтор, мы просто не выиграем по
счету. Вроде логично. Ок, попробую, но походу у меня пока вообще никакая проверка на повтор не реализована, надо заняться.

Делать попиксельное условие трудно - нужно иметь обратную мапу диапазонов, чтобы исходя из глобального индекса пикселя понять с какого спрайта нам начинать. Можно это сделать, но как-нибудь потом, когда нечем
будет заняться. А пока что легче сделать поспрайтовое условие - оно будет нормально работать если в первой половине будет примерно столько же пискелей сколько во второй. Можно в принципе об этом заботиться на
этапе упаковки.

Шикарно! Просто шикарно. Ускорились очень хорошо - до 160 сек!! Это с обеими оптимизациями. Можно конечно попробовать их по-отдельности чисто для теста, хотя я уверен, что результат будет хуже.
*/


#define BLOCK_SIZE 1024
#define WARP_SIZE 32
#define DIVERGENCE_CONTROL_CYCLE 128 //Через какое кол-во операций мы проверяем на необходимость ужатия, чтобы избежать дивергенции?
#define DIVERGENCE_CONTROL_THRESHOLD 32 //Если какое число потоков простаивают надо ужимать? Думаю это значение вряд ли когда-нибудь изменится.
#define REGISTRY_STRUCTURE_LENGTH 12
#define SIZING_STRUCTURE_LENGTH 4
#define DATA_STRUCTURE_LENGTH 4
#define RESERVED_DATA_LENGHT 2
#define INDECIES_INFO_LENGHT 8
#define RGBA_FLAGS_UTILIZING false

#define MAX_FLAGS_LENGTH_FOR_SPRITE 8192 //Для 256х256 спрайта он именно такой

#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }
inline void gpuAssert(cudaError_t code, const char* file, int line, bool abort = true)
{
	if (code != cudaSuccess)
	{
		fprintf(stderr, "GPUassert: %s %s %d\n", cudaGetErrorString(code), file, line);
		if (abort) exit(code);
	}
}

__constant__ short SizingsCount;
__constant__ short SpritesCount;
__constant__ int ByteLineLength;
__constant__ int BitLineLength;
__constant__ unsigned int ScoresCount;
__constant__ int OptimizedScoresCount;

__constant__ short SizingWidths[22];
__constant__ short SizingHeights[22];
__constant__ int SpriteByteOffsets[650];
__constant__ int SpriteBitOffsets[650];
__constant__ short SpriteWidths[650];
__constant__ short SpriteHeights[650];
__constant__ int VoidOffsets[14300];

__device__ unsigned int getRemainder(int value, int divider)
{
	return value % divider;
	/*int quotent = __fdividef(value, divider);
	return value - (divider * quotent);*/
}

__device__ unsigned int ceilToInt(int value, int const divider)
{
	int quotent = value / divider;
	int remainder = value - (divider * quotent);
	if (remainder == 0)
		return quotent;
	else
		return quotent + 1;
}

int hostCeilToInt(int value, int divider)
{
	if (value % divider == 0)
		return value / divider;
	else
		return value / divider + 1;
}

__global__ void countScores(unsigned char* rgbaData, unsigned char* voids, unsigned char* rgbaFlags, unsigned int* workingOffsets, int* results, unsigned int* indeciesInfo)
{
	/*if (threadIdx.x == 0)
		printf("x = %d, z = %d\n", blockIdx.x, blockIdx.z);
	return;*/

	//int ourSpriteIndex = blockIdx.x;
	//int candidateSpriteIndex = candidateIndex;
	//int sizingIndex = blockIdx.z;

	//int ourByteOffset = SpriteByteOffsets[blockIdx.x];
	//int ourBitOffset = SpriteBitOffsets[blockIdx.x];
	//short ourWidth = SpriteWidths[blockIdx.x];
	//short ourHeight = SpriteHeights[blockIdx.x];
	//int ourSquare = SpriteWidths[blockIdx.x] * SpriteHeights[blockIdx.x];
	/*int ourBitsSquare = (SpriteWidths[blockIdx.x] * SpriteHeights[blockIdx.x]) / 8;
	if ((SpriteWidths[blockIdx.x] * SpriteHeights[blockIdx.x]) % 8 != 0)
		ourBitsSquare++;*/

		//short sizingWidth = SizingWidths[blockIdx.z];
		//short sizingHeight = SizingHeights[blockIdx.z];

		//__shared__ char ourRFlags[MAX_FLAGS_LENGTH_FOR_SPRITE];
		//__shared__ char ourGFlags[MAX_FLAGS_LENGTH_FOR_SPRITE];
		//__shared__ char candidateRFlags[MAX_FLAGS_LENGTH_FOR_SPRITE];
		//__shared__ char candidateGFlags[MAX_FLAGS_LENGTH_FOR_SPRITE];
		//__shared__ char candidateVoidMap[MAX_FLAGS_LENGTH_FOR_SPRITE];//Экономим регистры
	__shared__ unsigned char cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE * 5];

	//int numberOfTimesWeNeedToLoadSelf = ceilToInt(SpriteWidths[blockIdx.x] * SpriteHeights[blockIdx.x], 8) / BLOCK_SIZE; // ceilToInt(ceilToInt(SpriteWidths[blockIdx.x] * SpriteHeights[blockIdx.x], 8), BLOCK_SIZE)
	//if (ceilToInt(SpriteWidths[blockIdx.x] * SpriteHeights[blockIdx.x], 8) % BLOCK_SIZE != 0)
	//	numberOfTimesWeNeedToLoadSelf++;

	int temp;
	size_t i;
	if (RGBA_FLAGS_UTILIZING)
	{
		for (i = 0; i < ceilToInt(ceilToInt(SpriteWidths[blockIdx.x] * SpriteHeights[blockIdx.x], 8), BLOCK_SIZE); i++)// - КЭШ
		{
			temp = i * BLOCK_SIZE + threadIdx.x;
			if (temp >= ceilToInt(SpriteWidths[blockIdx.x] * SpriteHeights[blockIdx.x], 8))
				continue;
			cachedBits[temp] = rgbaFlags[SpriteBitOffsets[blockIdx.x] + temp];
			cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE + temp] = rgbaFlags[BitLineLength + SpriteBitOffsets[blockIdx.x] + temp];
		}
	}
	/*__syncthreads();
	if (blockIdx.x == 7 && blockIdx.z == 0 && threadIdx.x == 0)
	{
		printf("The 0'th byte of rgbaFlags (sprite#0) of R is %d\n", rgbaFlags[SpriteBitOffsets[0]]);
		printf("The 0'th byte of rgbaFlags (sprite#0) of G is %d\n", rgbaFlags[BitLineLength + SpriteBitOffsets[0]]);
		printf("The 0'th byte of rgbaFlags (sprite#0) of B is %d\n", rgbaFlags[BitLineLength * 2 + SpriteBitOffsets[0]]);
		printf("The 0'th byte of rgbaFlags (sprite#0) of A is %d\n", rgbaFlags[BitLineLength * 3 + SpriteBitOffsets[0]]);
		printf("The 0'th byte of rgbaFlags (sprite#7) of R is %d\n", rgbaFlags[SpriteBitOffsets[7]]);
		printf("The 0'th byte of rgbaFlags (sprite#7) of G is %d\n", rgbaFlags[BitLineLength + SpriteBitOffsets[7]]);
		printf("The 0'th byte of rgbaFlags (sprite#7) of B is %d\n", rgbaFlags[BitLineLength * 2 + SpriteBitOffsets[7]]);
		printf("The 0'th byte of rgbaFlags (sprite#7) of A is %d\n", rgbaFlags[BitLineLength * 3 + SpriteBitOffsets[7]]);

		printf("The 2'th byte of rgbaFlags (sprite#0) of R is %d\n", rgbaFlags[SpriteBitOffsets[0] + 2]);
		printf("The 2'th byte of rgbaFlags (sprite#0) of G is %d\n", rgbaFlags[BitLineLength + SpriteBitOffsets[0] + 2]);
		printf("The 2'th byte of rgbaFlags (sprite#0) of B is %d\n", rgbaFlags[BitLineLength * 2 + SpriteBitOffsets[0] + 2]);
		printf("The 2'th byte of rgbaFlags (sprite#0) of A is %d\n", rgbaFlags[BitLineLength * 3 + SpriteBitOffsets[0] + 2]);
		printf("The 2'th byte of rgbaFlags (sprite#7) of R is %d\n", rgbaFlags[SpriteBitOffsets[7] + 2]);
		printf("The 2'th byte of rgbaFlags (sprite#7) of G is %d\n", rgbaFlags[BitLineLength + SpriteBitOffsets[7] + 2]);
		printf("The 2'th byte of rgbaFlags (sprite#7) of B is %d\n", rgbaFlags[BitLineLength * 2 + SpriteBitOffsets[7] + 2]);
		printf("The 2'th byte of rgbaFlags (sprite#7) of A is %d\n", rgbaFlags[BitLineLength * 3 + SpriteBitOffsets[7] + 2]);

		printf("Cached 0'th byte of rgbaFlags (sprite#0) of R is %d\n", cachedBits[0]);
		printf("Cached 0'th byte of rgbaFlags (sprite#0) of G is %d\n", cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE+0]);
	}
	return;*/

	int ourWorkingHeight = SpriteHeights[blockIdx.x] - SizingHeights[blockIdx.z] + 1;
	//int ourWorkingSquare = (SpriteWidths[blockIdx.x] - SizingWidths[blockIdx.z]) * ourWorkingHeight;
	int numberOfTasksPerThread = ((SpriteWidths[blockIdx.x] - SizingWidths[blockIdx.z] + 1) * ourWorkingHeight) / BLOCK_SIZE; // ceilToInt((SpriteWidths[blockIdx.x] - SizingWidths[blockIdx.z]) * ourWorkingHeight, BLOCK_SIZE)
	if (((SpriteWidths[blockIdx.x] - SizingWidths[blockIdx.z] + 1) * ourWorkingHeight) % BLOCK_SIZE != 0)
		numberOfTasksPerThread++;

	//int sizingSquare = SizingWidths[blockIdx.z] * SizingHeights[blockIdx.z];


	//ОК, почему мы проходимся сначала по кандидатским спрайтам, а уже в них - по пикселям нашего спрайта? Потому что если мы сначала будем проходиться по пикселям, то каждый кандидат будет загружен такое кол-во раз, какое кол-во пикселей обрабатывает каждый тред.

	/*
	Ок, тут будет первая часть оптимизации повторов. Если наш целевой спрайт находится во второй половине БД мы не проверяем первую. Потому что если там что-то есть то мы повтор, а узнаем мы об этом только обработав большую половину бд, т.е. слишком поздно, чтобы оптимизация
	работала. Так что игнорим все спрайты что до нас - если мы повтор, мы просто не выиграем у не-повтора из спрайта до нас. Эта оптимизация будет работать без второй половины? Да, будет. На самом деле она может работать и самостоятельно, если убрать условие и просто всегда
	начинать с собственного спрайта. Но в этом случае для спрайтов, находящихся в первой половине, возможно, будет производиться ненужная работа - они никогда не узнают, если они повторы, и поэтому будут в любом случае обрабатывать большую часть бд, хотя могли бы отдыхать.
	*/
	for (size_t candidateIndex = blockIdx.x >= SpritesCount / 2 ? blockIdx.x : 0; candidateIndex < SpritesCount; candidateIndex++)
	{
		int candidateWorkingWidth = SpriteWidths[candidateIndex] - SizingWidths[blockIdx.z] + 1;
		int candidateWorkingHeight = SpriteHeights[candidateIndex] - SizingHeights[blockIdx.z] + 1;

		/*int candidateByteOffset = SpriteByteOffsets[candidateIndex];
		int candidateBitOffset = SpriteBitOffsets[candidateIndex];*/
		//int candidateWidth = SpriteWidths[candidateIndex];
		//int candidateHeight = SpriteHeights[candidateIndex];
		//int candidateSquare = SpriteWidths[candidateIndex] * SpriteHeights[candidateIndex];

		__syncthreads(); // - это очень важно, ок? Без этой синхронизации, некоторые варпы будут опережать другие и начинать грузить в память блока новые куски данных, хотя другие варпы все еще хотят юзать старую память.


		if (RGBA_FLAGS_UTILIZING)
		{
			int candidateBitsSquare = (SpriteWidths[candidateIndex] * SpriteHeights[candidateIndex]) / 8;
			if ((SpriteWidths[candidateIndex] * SpriteHeights[candidateIndex]) % 8 != 0)
				candidateBitsSquare++;

			int numberOfTimesWeNeedToLoadCandidate = (candidateBitsSquare / BLOCK_SIZE);
			if (candidateBitsSquare % BLOCK_SIZE != 0)
				numberOfTimesWeNeedToLoadCandidate++;

			for (i = 0; i < numberOfTimesWeNeedToLoadCandidate; i++)// - КЭШ
			{
				temp = i * BLOCK_SIZE + threadIdx.x;
				if (temp >= candidateBitsSquare)
					continue;
				cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE * 2 + temp] = rgbaFlags[SpriteBitOffsets[candidateIndex] + temp];
				cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE * 3 + temp] = rgbaFlags[BitLineLength + SpriteBitOffsets[candidateIndex] + temp];
			}
		}


		//int candidateWidthMinusSizing = SpriteWidths[candidateIndex] - SizingWidths[blockIdx.z];
		//int candidateHeightMinusSizing = SpriteHeights[candidateIndex] - SizingHeights[blockIdx.z];
		//int candidateVoidAreaSquare = (SpriteWidths[candidateIndex] - SizingWidths[blockIdx.z]) * (SpriteHeights[candidateIndex] - SizingHeights[blockIdx.z]);
		int candidateVoidAreaBitSquare = (candidateWorkingWidth * candidateWorkingHeight) / 8;
		if ((candidateWorkingWidth * candidateWorkingHeight) % 8 != 0)
			candidateVoidAreaBitSquare++;

		int numberOfTimesWeNeedToLoadVoid = candidateVoidAreaBitSquare / BLOCK_SIZE;
		if (candidateVoidAreaBitSquare % BLOCK_SIZE != 0)
			numberOfTimesWeNeedToLoadVoid++;

		temp = VoidOffsets[candidateIndex * SizingsCount + blockIdx.z];
		unsigned char* candidateVoidMapGlobal = voids + temp;

		//if (blockIdx.x == 7 && candidateIndex == 7 && blockIdx.z == 18 && threadIdx.x < candidateVoidAreaSquare)
		//{
		//	int candidateX = threadIdx.x / (SpriteHeights[candidateIndex] - SizingHeights[blockIdx.z]);
		//	int candidateY = threadIdx.x % (SpriteHeights[candidateIndex] - SizingHeights[blockIdx.z]);
		//	printf("	void (%d, %d): %d\n", candidateX, candidateY, candidateVoidMapGlobal[threadIdx.x / 8] >> threadIdx.x % 8 & 1);
		//} //Проверили правильность апрсинга войдмап


		//if (blockIdx.x == 7 && blockIdx.z == 18 && threadIdx.x == 0)
		//{
		//	printf("Void offset: %d\n", VoidOffsets[blockIdx.x * SizingsCount + blockIdx.z]);
		//	printf("candidateIndex * SizingsCount + blockIdx.z: %d\n", blockIdx.x * SizingsCount + blockIdx.z);
		//	printf("VoidOffsets[0]: %d\n", VoidOffsets[0]);
		//}
		////Проверили правильность смещения войдмап


		for (i = 0; i < numberOfTimesWeNeedToLoadVoid; i++)// - КЭШ
		{
			temp = i * BLOCK_SIZE + threadIdx.x;
			if (temp >= candidateVoidAreaBitSquare)
				continue;
			cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE * 4 + temp] = candidateVoidMapGlobal[temp];
		}

		__syncthreads(); //Обязательна синхронизация для того, чтобы потоки, которые не выполняли загрузку в шаред-память, не начали с этой шаред памятью работать, пока другие в нее еще не все загрузили, ибо результат - непредсказуем.

		//Проверяем, что все скопировалось правильно. Для этого выбираем случайный спрайт и логируем его флаги. Пускай будет спрайт №7
		//if (blockIdx.x == 7 && blockIdx.z == 18) //Так мы обойдемся без повторов, только 1 блок будет логировать
		//{
		//	if (threadIdx.x < SpriteWidths[blockIdx.x] * SpriteHeights[blockIdx.x])
		//	{
		//		int x = threadIdx.x / BLOCK_SIZE;
		//		int y = threadIdx.x % BLOCK_SIZE;
		//		printf("for pixel #%d (%d, %d) the flags of r and g are (%d, %d) == (%d, %d)\n", threadIdx.x, x, y, (cachedBits[threadIdx.x / 8] >> (threadIdx.x % 8)) & 1, (cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE + threadIdx.x / 8] >> (threadIdx.x % 8)) & 1, (cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE * 2 + threadIdx.x / 8] >> (threadIdx.x % 8)) & 1, (cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE * 3 + threadIdx.x / 8] >> (threadIdx.x % 8)) & 1);
		//	}
		//} //Проверил, работает

		//if (blockIdx.x == 7 && blockIdx.z == 18 && threadIdx.x < (SpriteWidths[candidateIndex] - SizingWidths[blockIdx.z]) * (SpriteHeights[candidateIndex] - SizingHeights[blockIdx.z]))
		//{
		//	int candidateX = threadIdx.x / (SpriteHeights[blockIdx.x] - SizingHeights[blockIdx.z] + 1);
		//	int candidateY = threadIdx.x % (SpriteHeights[blockIdx.x] - SizingHeights[blockIdx.z] + 1);
		//	printf("	void (%d, %d): %d\n", candidateX, candidateY, cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE * 4 + threadIdx.x / 8] >> threadIdx.x % 8 & 1);
		//} //Проверили правильность парсинга войдмап
		//return;

		for (size_t taskIndex = 0; taskIndex < numberOfTasksPerThread; taskIndex++)
		{
			int ourWorkingPixelIndex = taskIndex * BLOCK_SIZE + threadIdx.x;
			if (ourWorkingPixelIndex >= (SpriteWidths[blockIdx.x] - SizingWidths[blockIdx.z] + 1) * ourWorkingHeight)
				break;

			/*if ((int)((cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE * 4 + ourWorkingPixelIndex / 8] >> (ourWorkingPixelIndex % 8)) & 1) == 0)
				continue;*/
			if ((int)((voids + VoidOffsets[blockIdx.x * SizingsCount + blockIdx.z])[ourWorkingPixelIndex / 8] >> (ourWorkingPixelIndex % 8) & 1) == 0)
				continue;

			int ourWorkingX = (ourWorkingPixelIndex / ourWorkingHeight);
			int ourWorkingY = ourWorkingPixelIndex % ourWorkingHeight;

			if (results[(workingOffsets[blockIdx.x * SizingsCount + blockIdx.z] + ourWorkingX * ourWorkingHeight + ourWorkingY)] < 0)
				continue;

			bool isRepeat = false;

			/*if (taskIndex == 0)
				results[(workingOffsets[blockIdx.x * SizingsCount + blockIdx.z] + ourWorkingX * ourWorkingHeight + ourWorkingY)] = 0;*/
				//int coincidences = 0; //Значения меньше 0 - повторы

			//Считаем счет. Мда.
			temp = 0;
			size_t x;
			size_t y;
			for (x = 0; x < SizingWidths[blockIdx.z]; x++)
			{
				for (y = 0; y < SizingHeights[blockIdx.z]; y++)
				{
					i = (ourWorkingX + x) * SpriteHeights[blockIdx.x] + ourWorkingY + y;
					if (rgbaData[ByteLineLength * 3 + SpriteByteOffsets[blockIdx.x] + i] > 0)
						temp++;
				}
			}
			i = (SizingWidths[blockIdx.z] * SizingHeights[blockIdx.z]);
			temp = temp * temp * temp;
			temp = __fdividef(temp, i);

			int coincidences = 0;

			for (size_t candidateWorkingX = 0; candidateWorkingX < candidateWorkingWidth; candidateWorkingX++)
			{
				for (size_t candidateWorkingY = 0; candidateWorkingY < candidateWorkingHeight; candidateWorkingY++)
				{
					int candidatePixelIndex = candidateWorkingX * candidateWorkingHeight + candidateWorkingY;
					if ((int)((cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE * 4 + candidatePixelIndex / 8] >> (candidatePixelIndex % 8)) & 1) == 0)
						continue;

					bool isTheSame = true;
					for (x = 0; x < SizingWidths[blockIdx.z]; x++)
					{
						for (y = 0; y < SizingHeights[blockIdx.z]; y++)
						{
							i = (ourWorkingX + x) * SpriteHeights[blockIdx.x] + ourWorkingY + y;
							int candidatePixelIndex = (candidateWorkingX + x) * SpriteHeights[candidateIndex] + candidateWorkingY + y;

							/*
							Ок, еще одна важная деталь - проверка прозрачных пикселей должна быть ВСЕГДА БЛЕАТЬ ПЕРЕД проверкой цвета.
							*/

							/*
							Хм... Если у нас кандидатский пиксель прозрачный и наш прозрачный, то нам, конечно, неважно, какие там дальше цвета - нам такой пиксель подходит. Но. Если пиксель-кандидат прозрачный, а наш нет, то нам такой пиксель полюбому ведь НЕ подходит, верно?
							А если кандидатский НЕ прозрачный, а наш прозрачный? Тоже не подходит. В общем прозрачность можно использовать как хороший такой гейт. Прозрачный - continue и не проверяем остальное, иначе - break. Нет, не так. Если обе прозрачности одинаковые, то
							если одна из них равна 0 - continue, иначе break
							*/

							if (rgbaData[ByteLineLength * 3 + SpriteByteOffsets[candidateIndex] + candidatePixelIndex] == rgbaData[ByteLineLength * 3 + SpriteByteOffsets[blockIdx.x] + i])
							{
								if (rgbaData[ByteLineLength * 3 + SpriteByteOffsets[blockIdx.x] + i] == 0)
									continue;
							}
							else
							{
								isTheSame = false;
								break;
							}

							if (RGBA_FLAGS_UTILIZING)
							{
								if ((int)(((int)cachedBits[(int)i / 8] >> ((int)i % 8)) & 1) != (int)(((int)cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE * 2 + candidatePixelIndex / 8] >> (candidatePixelIndex % 8)) & 1)) //Эти инты ((int)), оборачивающие выражение вплоть до "& 1" очень важны. Это очень забавно, ха-ха, но без них 1 != 1, прикольненько.
								{
									isTheSame = false;
									break;
								}
								if ((int)(((int)cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE + (int)i / 8] >> ((int)i % 8)) & 1) != (int)(((int)cachedBits[MAX_FLAGS_LENGTH_FOR_SPRITE * 3 + candidatePixelIndex / 8] >> (candidatePixelIndex % 8)) & 1)) //Эти инты ((int)), оборачивающие выражение вплоть до "& 1" очень важны. Это очень забавно, ха-ха, но без них 1 != 1, прикольненько.
								{
									isTheSame = false;
									break;
								}
							}

							if (rgbaData[SpriteByteOffsets[blockIdx.x] + i] != rgbaData[SpriteByteOffsets[candidateIndex] + candidatePixelIndex])
							{
								isTheSame = false;
								break;
							}
							if (rgbaData[ByteLineLength + SpriteByteOffsets[blockIdx.x] + i] != rgbaData[ByteLineLength + SpriteByteOffsets[candidateIndex] + candidatePixelIndex])
							{
								isTheSame = false;
								break;
							}
							if (rgbaData[ByteLineLength * 2 + SpriteByteOffsets[blockIdx.x] + i] != rgbaData[ByteLineLength * 2 + SpriteByteOffsets[candidateIndex] + candidatePixelIndex])
							{
								isTheSame = false;
								break;
							}
						}

						if (!isTheSame)
							break;
					}

					if (isTheSame)
					{
						if (blockIdx.x > candidateIndex)
						{
							isRepeat = true;
							break;
						}

						coincidences++;
					}
				}

				if (isRepeat)
					break;
			}

			if (isRepeat)
				results[(workingOffsets[blockIdx.x * SizingsCount + blockIdx.z] + ourWorkingX * ourWorkingHeight + ourWorkingY)] = -1;
			else
			{
				results[(workingOffsets[blockIdx.x * SizingsCount + blockIdx.z] + ourWorkingX * ourWorkingHeight + ourWorkingY)] += coincidences * temp;
				if (taskIndex == 0) //У каждого треда может быть много заданий. Нет смысла записывать много раз одни и те же данные.
				{
					indeciesInfo[(workingOffsets[blockIdx.x * SizingsCount + blockIdx.z] + ourWorkingX * ourWorkingHeight + ourWorkingY)] = blockIdx.x;
					indeciesInfo[OptimizedScoresCount + (workingOffsets[blockIdx.x * SizingsCount + blockIdx.z] + ourWorkingX * ourWorkingHeight + ourWorkingY)] = blockIdx.z;
				}
			}
		}
	}
}

__global__ void findTheBestScore(int* scores, unsigned int* indecies, unsigned int* indeciesInfo, int depth, int currentScoresLength, int allScoresLength)
{
	/*if (blockIdx.x == 0 && threadIdx.x == 0)
		printf("depth = %d, currentScoresLength = %d\n", depth, currentScoresLength);*/
		/*
			Сначала надо всегда искать победителя в варпе. Потом, когда в каждом варпе останется по 1 победителю - синхронизируются и 1й варп блока копирует себе все 31 значений других варпов и повторяет трюк.
		*/

		//printf("findTheBestScore!\n");
		///*if (blockIdx.x == 0 && threadIdx.x / 32 == 0)
		//{
		//	printf("findTheBestScore! It's %d-th thread talking\n", threadIdx.x);
		//}*/

		//return;

	int blockOffset = blockIdx.x * BLOCK_SIZE;
	int threadOffset = threadIdx.x;
	for (size_t i = 0; i < depth; i++)
	{
		blockOffset *= WARP_SIZE;
		threadOffset *= WARP_SIZE;
	}

	int scoreId = blockOffset + threadOffset;
	if (scoreId > allScoresLength)
		return;

	/*if (scoreId % 7863 < 1024 && depth == 0)
		printf("indeciesInfo[%d] = %d, indeciesInfo[%d] = %d\n", scoreId, indeciesInfo[scoreId], OptimizedScoresCount + scoreId, indeciesInfo[OptimizedScoresCount + scoreId]);*/

	int ourScore = scores[scoreId];
	int ourScoreBlockIdX = indeciesInfo[scoreId];
	int ourScoreBlockIdZ = indeciesInfo[OptimizedScoresCount + scoreId];
	int ourIndex = scoreId;
	if (depth > 0)
		ourIndex = indecies[scoreId];

	/*if (blockIdx.x == 0 && (threadIdx.x / 32) == 0)
	{
		printf("%d: ourIndex = %d, ourScore = %d\n", threadIdx.x, ourIndex, ourScore);
	}*/

	//return;

	int candidateScore = __shfl_down_sync(0xff, ourScore, 1, 2);
	int candidateIndex = __shfl_down_sync(0xff, ourIndex, 1, 2);
	int candidateBlockIdX = __shfl_down_sync(0xff, ourScoreBlockIdX, 1, 2);
	int candidateBlockIdZ = __shfl_down_sync(0xff, ourScoreBlockIdZ, 1, 2);
	if (threadIdx.x % 2 == 0)
	{
		if (candidateScore > ourScore)
		{
			ourScore = candidateScore;
			ourIndex = candidateIndex;
			ourScoreBlockIdX = candidateBlockIdX;
			ourScoreBlockIdZ = candidateBlockIdZ;
		}
	}

	candidateScore = __shfl_down_sync(0xff, ourScore, 2, 4);
	candidateIndex = __shfl_down_sync(0xff, ourIndex, 2, 4);
	candidateBlockIdX = __shfl_down_sync(0xff, ourScoreBlockIdX, 2, 4);
	candidateBlockIdZ = __shfl_down_sync(0xff, ourScoreBlockIdZ, 2, 4);
	if (threadIdx.x % 4 == 0)
	{
		if (candidateScore > ourScore)
		{
			ourScore = candidateScore;
			ourIndex = candidateIndex;
			ourScoreBlockIdX = candidateBlockIdX;
			ourScoreBlockIdZ = candidateBlockIdZ;
		}
	}

	candidateScore = __shfl_down_sync(0xff, ourScore, 4, 8);
	candidateIndex = __shfl_down_sync(0xff, ourIndex, 4, 8);
	candidateBlockIdX = __shfl_down_sync(0xff, ourScoreBlockIdX, 4, 8);
	candidateBlockIdZ = __shfl_down_sync(0xff, ourScoreBlockIdZ, 4, 8);
	if (threadIdx.x % 8 == 0)
	{
		if (candidateScore > ourScore)
		{
			ourScore = candidateScore;
			ourIndex = candidateIndex;
			ourScoreBlockIdX = candidateBlockIdX;
			ourScoreBlockIdZ = candidateBlockIdZ;
		}
	}

	candidateScore = __shfl_down_sync(0xff, ourScore, 8, 16);
	candidateIndex = __shfl_down_sync(0xff, ourIndex, 8, 16);
	candidateBlockIdX = __shfl_down_sync(0xff, ourScoreBlockIdX, 8, 16);
	candidateBlockIdZ = __shfl_down_sync(0xff, ourScoreBlockIdZ, 8, 16);
	if (threadIdx.x % 16 == 0)
	{
		if (candidateScore > ourScore)
		{
			ourScore = candidateScore;
			ourIndex = candidateIndex;
			ourScoreBlockIdX = candidateBlockIdX;
			ourScoreBlockIdZ = candidateBlockIdZ;
		}
	}

	candidateScore = __shfl_down_sync(0xff, ourScore, 16);
	candidateIndex = __shfl_down_sync(0xff, ourIndex, 16);
	candidateBlockIdX = __shfl_down_sync(0xff, ourScoreBlockIdX, 16);
	candidateBlockIdZ = __shfl_down_sync(0xff, ourScoreBlockIdZ, 16);
	if (threadIdx.x % 16 == 0)
	{
		if (candidateScore > ourScore)
		{
			ourScore = candidateScore;
			ourIndex = candidateIndex;
			ourScoreBlockIdX = candidateBlockIdX;
			ourScoreBlockIdZ = candidateBlockIdZ;
		}
	}

	scores[scoreId] = ourScore;
	indecies[scoreId] = ourIndex;
	indeciesInfo[scoreId] = ourScoreBlockIdX;
	indeciesInfo[OptimizedScoresCount + scoreId] = ourScoreBlockIdZ;
}

/*
	Ок, для удаления области из данных нам надо всего лишь пройтись по всем данным 1 раз - тривиально. И область виннера никогда не меняется. Она задана извне 1 раз, соответственно изменениям подвержены
	только переменные области кандидата.

	Ок, чтобы обновить войдмапы, нам не нужно проходиться по width и height. Нам нужны лишь координаты самой области
*/

__device__ void erase(unsigned char* rgbaData, unsigned char* voids, unsigned char* rgbaFlags, unsigned int spriteIndex, unsigned int sizingIndex, short x, short y, short sizingWidth, short sizingHeight, bool verbose)
{
	for (size_t currentSizingIndex = sizingIndex; currentSizingIndex < SizingsCount; currentSizingIndex++)
	{
		int spriteSizeVoidOffset = VoidOffsets[spriteIndex * SizingsCount + currentSizingIndex];
		unsigned char* currentSpriteSizeVoids = voids + spriteSizeVoidOffset;
		int currentSizingWidth = SizingWidths[currentSizingIndex];
		int currentSizingHeight = SizingHeights[currentSizingIndex];

		/*if (verbose)
			printf("erasing %d (%d, %d) from sprite %d and sizing %d (void offset %d)\n", (int)currentSizingIndex, currentSizingWidth, currentSizingHeight, spriteIndex, sizingIndex, spriteSizeVoidOffset);*/

		int diffWidth = sizingWidth - currentSizingWidth;
		int diffHeight = sizingHeight - currentSizingHeight;
		if (diffWidth < 0 || diffHeight < 0) //Это может быть, например, если сайзинг у нас 8,7 а мы спустились на 7,8 - пропускаем этот сайзинг.
			continue;
		/*printf("diffWidth = %d\n", diffWidth);
		printf("diffHeight = %d\n", diffHeight);
		if (diffWidth < 0)
			printf("diffWidth < 0, currentSizingIndex = %d (%d, %d), sizingIndex = %d (%d, %d)", (int)currentSizingIndex, currentSizingWidth, currentSizingHeight, sizingIndex, sizingWidth, sizingHeight);
		if (diffHeight < 0)
			printf("diffHeight < 0, currentSizingIndex = %d (%d, %d), sizingIndex = %d (%d, %d)", (int)currentSizingIndex, currentSizingWidth, currentSizingHeight, sizingIndex, sizingWidth, sizingHeight);*/

		for (size_t xx = 0; xx <= diffWidth; xx++)
		{
			//printf("xxx\n");
			for (size_t yy = 0; yy <= diffHeight; yy++)
			{
				//printf("yyy\n");
				int voidMapIndex = (x + xx) * (SpriteHeights[spriteIndex] - currentSizingHeight + 1) + y + yy;
				/*if (verbose)
				{
					int was = currentSpriteSizeVoids[voidMapIndex / 8];
					currentSpriteSizeVoids[voidMapIndex / 8] &= ~(1 << (voidMapIndex % 8));
					int became = currentSpriteSizeVoids[voidMapIndex / 8];
					printf("	erasing at %d,%d. Was %d, became %d\n", (int)(x + xx), (int)(y + yy), (int)((was >> (voidMapIndex % 8)) & 1), (int)((became >> (voidMapIndex % 8)) & 1));
				}
				else*/
				currentSpriteSizeVoids[voidMapIndex / 8] &= ~(1 << (voidMapIndex % 8));
			}
		}
	}

	for (size_t xx = 0; xx < sizingWidth; xx++)
	{
		for (size_t yy = 0; yy < sizingHeight; yy++)
		{
			int pixelIndex = (x + xx) * SpriteHeights[spriteIndex] + y + yy;
			//if (verbose)
			//{
			//	printf("%d\n", x + xx);
			//	printf("%d\n", y + yy);
			//	printf("%d\n", rgbaData[SpriteByteOffsets[spriteIndex] + pixelIndex]);
			//	printf("%d\n", rgbaData[ByteLineLength + SpriteByteOffsets[spriteIndex] + pixelIndex]);
			//	printf("%d\n", rgbaData[ByteLineLength * 2 + SpriteByteOffsets[spriteIndex] + pixelIndex]);
			//	printf("%d\n", rgbaData[ByteLineLength * 3 + SpriteByteOffsets[spriteIndex] + pixelIndex]);
			//	printf("\n");
			//	//printf("Verbose erasing: (%d, %d) = (%d, %d, %d, %d), test = %d\n", x + xx, y + yy, rgbaData[SpriteByteOffsets[spriteIndex] + pixelIndex], rgbaData[ByteLineLength + SpriteByteOffsets[spriteIndex] + pixelIndex], rgbaData[ByteLineLength * 2 + SpriteByteOffsets[spriteIndex] + pixelIndex], rgbaData[ByteLineLength * 3 + SpriteByteOffsets[spriteIndex] + pixelIndex], 121212);
			//}
			rgbaData[SpriteByteOffsets[spriteIndex] + pixelIndex] = 0;
			rgbaData[ByteLineLength + SpriteByteOffsets[spriteIndex] + pixelIndex] = 0;
			rgbaData[ByteLineLength * 2 + SpriteByteOffsets[spriteIndex] + pixelIndex] = 0;
			rgbaData[ByteLineLength * 3 + SpriteByteOffsets[spriteIndex] + pixelIndex] = 0;

			if (RGBA_FLAGS_UTILIZING)
			{
				rgbaFlags[SpriteBitOffsets[spriteIndex] + pixelIndex / 8] &= ~(1 << (pixelIndex % 8));
				rgbaFlags[BitLineLength + SpriteBitOffsets[spriteIndex] + pixelIndex / 8] &= ~(1 << (pixelIndex % 8));
				rgbaFlags[BitLineLength * 2 + SpriteBitOffsets[spriteIndex] + pixelIndex / 8] &= ~(1 << (pixelIndex % 8));
				rgbaFlags[BitLineLength * 3 + SpriteBitOffsets[spriteIndex] + pixelIndex / 8] &= ~(1 << (pixelIndex % 8));
			}
		}
	}
}

__device__ bool doOverlap(short x1, short y1, short w1, short h1, short x2, short y2, short w2, short h2)
{
	if (x1 >= x2 + w2 || x2 >= x1 + w1)
		return false;
	if (y1 >= y2 + h2 || y2 >= y1 + h1)
		return false;
	return true;

	//// If one rectangle is on left side of other 
	//if (l1.x > r2.x || l2.x > r1.x)
	//	return false;

	//// If one rectangle is above other 
	//if (l1.y < r2.y || l2.y < r1.y)
	//	return false;

	//return true;
}

__global__ void stripTheWinnerAreaFromData(unsigned char* rgbaData, unsigned char* voids, unsigned char* rgbaFlags, unsigned int winnerSpriteIndex, unsigned int winnerSizing, unsigned short winnerX, unsigned short winnerY, unsigned short winnerWidth, unsigned short winnerHeight, unsigned int atlasIndex, unsigned int* offsets, unsigned int* numbersOfStrippings)
{
	short candidateWorkingWidth = SpriteWidths[blockIdx.x] - winnerWidth + 1;
	short candidateWorkingHeight = SpriteHeights[blockIdx.x] - winnerHeight + 1;

	//int candidateWorkingSquare = (SpriteWidths[blockIdx.x] - winnerWidth + 1) * candidateWorkingHeight;
	//int numberOfTasksPerThread = (candidateWorkingWidth * candidateWorkingHeight) / BLOCK_SIZE; // ceilToInt((SpriteWidths[blockIdx.x] - SizingWidths[blockIdx.z]) * ourWorkingHeight, BLOCK_SIZE)
	//if (candidateWorkingWidth * candidateWorkingHeight % BLOCK_SIZE != 0)
	//	numberOfTasksPerThread++;

	//printf("This is %dth blockx. My sprites square = %d (%d * %d)\n", blockIdx.x, candidateWorkingSquare, (SpriteWidths[blockIdx.x] - winnerWidth + 1), candidateWorkingHeight);
	//return;

	unsigned int numberOfStrippings = 0;
	unsigned int numberOfPixelsChecked = 0;
	for (size_t candidateWorkingX = 0; candidateWorkingX < candidateWorkingWidth; candidateWorkingX++)
	{
		for (size_t candidateWorkingY = 0; candidateWorkingY < candidateWorkingHeight; candidateWorkingY++)
		{
			numberOfPixelsChecked++;
			bool isTheSame = true;
			for (size_t x = 0; x < winnerWidth; x++)
			{
				for (size_t y = 0; y < winnerHeight; y++)
				{
					int ourWinnerPixelIndex = (winnerX + x) * SpriteHeights[winnerSpriteIndex] + winnerY + y;
					int candidatePixelIndex = (candidateWorkingX + x) * SpriteHeights[blockIdx.x] + candidateWorkingY + y;

					if (ourWinnerPixelIndex == candidatePixelIndex && blockIdx.x == winnerSpriteIndex)
					{
						isTheSame = false;
						break; //Мы не можем здесь очищать исходную область, т.к. она нужна нам для сравнения с ней, если мы ее обнулим поведение будет undefined. Очищаем исходную область мы в главном кернеле.
					}

					if (rgbaData[SpriteByteOffsets[winnerSpriteIndex] + ourWinnerPixelIndex] != rgbaData[SpriteByteOffsets[blockIdx.x] + candidatePixelIndex])
					{
						isTheSame = false;
						break;
					}
					if (rgbaData[ByteLineLength + SpriteByteOffsets[winnerSpriteIndex] + ourWinnerPixelIndex] != rgbaData[ByteLineLength + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex])
					{
						isTheSame = false;
						break;
					}
					if (rgbaData[ByteLineLength * 2 + SpriteByteOffsets[winnerSpriteIndex] + ourWinnerPixelIndex] != rgbaData[ByteLineLength * 2 + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex])
					{
						isTheSame = false;
						break;
					}
					if (rgbaData[ByteLineLength * 3 + SpriteByteOffsets[winnerSpriteIndex] + ourWinnerPixelIndex] != rgbaData[ByteLineLength * 3 + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex])
					{
						isTheSame = false;
						break;
					}
				}

				if (!isTheSame)
					break;
			}

			//Тут мы теперь дополнительно делаем чертовски необходимую проверку на перекрытие областей. Т.е. недостаточно, чтобы области совпадали. Если спрайт 1 и тот же - важно чтобы они не перекрывались, 
			//чтобы не повредить изначальную область.
			if (isTheSame && (blockIdx.x != winnerSpriteIndex || !doOverlap(winnerX, winnerY, winnerWidth, winnerHeight, candidateWorkingX, candidateWorkingY, winnerWidth, winnerHeight)))
			{
				erase(rgbaData, voids, rgbaFlags, blockIdx.x, winnerSizing, candidateWorkingX, candidateWorkingY, winnerWidth, winnerHeight, false);
				/*for (size_t x = 0; x < winnerWidth; x++)
				{
					for (size_t y = 0; y < winnerHeight; y++)
					{
						int candidatePixelIndex = (candidateWorkingX + x) * SpriteHeights[blockIdx.x] + candidateWorkingY + y;
						rgbaData[SpriteByteOffsets[blockIdx.x] + candidatePixelIndex] = 0;
						rgbaData[ByteLineLength + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex] = 0;
						rgbaData[ByteLineLength * 2 + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex] = 0;
						rgbaData[ByteLineLength * 3 + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex] = 0;
					}
				}*/

				offsets[SpriteByteOffsets[blockIdx.x] + candidateWorkingX * SpriteHeights[blockIdx.x] + candidateWorkingY] = atlasIndex + 1; //+1 потому что мы хотим чтобы 0 обозначал отсутствие в этом пикселе начала области атласа, а не 0ую область атласа
				numberOfStrippings++;
				//printf("isTheSame!!!!! numberOfStrippings = %d, blockIdx.x = %d, candidateWorkingX = %d, candidateWorkingY = %d\n", numberOfStrippings, blockIdx.x, candidateWorkingX, candidateWorkingY);
			}
		}
	}

	//printf("blockIdx.x = %d, numberOfStrippings = %d, numberOfPixelsChecked = %d\n", blockIdx.x, numberOfStrippings, numberOfPixelsChecked);
	numbersOfStrippings[blockIdx.x] = numberOfStrippings;

	//for (size_t candidateWorkingPixelIndex = 0; candidateWorkingPixelIndex < candidateWorkingSquare; candidateWorkingPixelIndex++)
	//{
	//	/*int candidateWorkingPixelIndex = taskIndex * BLOCK_SIZE + threadIdx.x;
	//	if (candidateWorkingPixelIndex >= candidateWorkingWidth * candidateWorkingHeight)
	//		break;*/

	//	short candidateWorkingX = (candidateWorkingPixelIndex / candidateWorkingHeight);
	//	short candidateWorkingY = candidateWorkingPixelIndex % candidateWorkingHeight;

	//	bool isTheSame = true;
	//	for (size_t x = 0; x < winnerWidth; x++)
	//	{
	//		for (size_t y = 0; y < winnerHeight; y++)
	//		{
	//			int ourWinnerPixelIndex = (winnerX + x) * SpriteHeights[winnerSpriteIndex] + winnerY + y;
	//			int candidatePixelIndex = (candidateWorkingX + x) * SpriteHeights[blockIdx.x] + candidateWorkingY + y;

	//			if (ourWinnerPixelIndex == candidatePixelIndex && blockIdx.x == winnerSpriteIndex)
	//			{
	//				isTheSame = false;
	//				break; //Мы не можем здесь очищать исходную область, т.к. она нужна нам для сравнения с ней, если мы ее обнулим поведение будет undefined. Очищаем исходную область мы в главном кернеле.
	//			}

	//			if (rgbaData[SpriteByteOffsets[winnerSpriteIndex] + ourWinnerPixelIndex] != rgbaData[SpriteByteOffsets[blockIdx.x] + candidatePixelIndex])
	//			{
	//				isTheSame = false;
	//				break;
	//			}
	//			if (rgbaData[ByteLineLength + SpriteByteOffsets[winnerSpriteIndex] + ourWinnerPixelIndex] != rgbaData[ByteLineLength + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex])
	//			{
	//				isTheSame = false;
	//				break;
	//			}
	//			if (rgbaData[ByteLineLength * 2 + SpriteByteOffsets[winnerSpriteIndex] + ourWinnerPixelIndex] != rgbaData[ByteLineLength * 2 + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex])
	//			{
	//				isTheSame = false;
	//				break;
	//			}
	//			if (rgbaData[ByteLineLength * 3 + SpriteByteOffsets[winnerSpriteIndex] + ourWinnerPixelIndex] != rgbaData[ByteLineLength * 3 + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex])
	//			{
	//				isTheSame = false;
	//				break;
	//			}
	//		}

	//		if (!isTheSame)
	//			break;
	//	}

	//	if (isTheSame)
	//	{
	//		erase(rgbaData, blockIdx.x, candidateWorkingX, candidateWorkingY, winnerWidth, winnerHeight);
	//		/*for (size_t x = 0; x < winnerWidth; x++)
	//		{
	//			for (size_t y = 0; y < winnerHeight; y++)
	//			{
	//				int candidatePixelIndex = (candidateWorkingX + x) * SpriteHeights[blockIdx.x] + candidateWorkingY + y;
	//				rgbaData[SpriteByteOffsets[blockIdx.x] + candidatePixelIndex] = 0;
	//				rgbaData[ByteLineLength + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex] = 0;
	//				rgbaData[ByteLineLength * 2 + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex] = 0;
	//				rgbaData[ByteLineLength * 3 + SpriteByteOffsets[blockIdx.x] + candidatePixelIndex] = 0;
	//			}
	//		}*/

	//		offsets[SpriteByteOffsets[blockIdx.x] + candidateWorkingX * SpriteHeights[blockIdx.x] + candidateWorkingY] = atlasIndex + 1; //+1 потому что мы хотим чтобы 0 обозначал отсутствие в этом пикселе начала области атласа, а не 0ую область атласа
	//		numberOfStrippings++;
	//		//printf("isTheSame!!!!! numberOfStrippings = %d, blockIdx.x = %d, candidateWorkingX = %d, candidateWorkingY = %d\n", numberOfStrippings, blockIdx.x, candidateWorkingX, candidateWorkingY);
	//	}
	//}

	//numberOfStrippings += __shfl_down_sync(0xff, numberOfStrippings, 16);
	//numberOfStrippings += __shfl_down_sync(0xff, numberOfStrippings, 8);
	//numberOfStrippings += __shfl_down_sync(0xff, numberOfStrippings, 4);
	//numberOfStrippings += __shfl_down_sync(0xff, numberOfStrippings, 2);
	//numberOfStrippings += __shfl_down_sync(0xff, numberOfStrippings, 1);

	//__shared__ unsigned short results[32];
	//if (threadIdx.x % 32 == 0)
	//{
	//	//numberOfStrippings += __shfl_down_sync(0xff, numberOfStrippings, 16);
	//	results[threadIdx.x / 32] = numberOfStrippings;
	//}

	//__syncthreads();
	//if (threadIdx.x < 32)
	//{
	//	numberOfStrippings = results[threadIdx.x];

	//	numberOfStrippings += __shfl_down_sync(0xff, numberOfStrippings, 16);
	//	numberOfStrippings += __shfl_down_sync(0xff, numberOfStrippings, 8);
	//	numberOfStrippings += __shfl_down_sync(0xff, numberOfStrippings, 4);
	//	numberOfStrippings += __shfl_down_sync(0xff, numberOfStrippings, 2);
	//	numberOfStrippings += __shfl_down_sync(0xff, numberOfStrippings, 1);

	//	if (threadIdx.x == 0)
	//	{
	//		numbersOfStrippings[blockIdx.x] = numberOfStrippings;
	//	}
	//}
}

__global__ void mainKernel(int opaquePixelsCount, unsigned char* rgbaData, unsigned char* voids, unsigned char* rgbaFlags, unsigned int* workingOffsets, int* scoresResults, unsigned int* indecies, unsigned int* indeciesInfo, unsigned int workingScoresLength, unsigned int optimizedWorkingScoresLength, char* atlas, unsigned int* offsets, unsigned int* spritesCountSizedArray, unsigned int* atlasLength)
{
	/*printf("main threadx = %d, blockx = %d", threadIdx.x, blockIdx.x);
	return;*/
	unsigned int currentIteration = 0;
	while (opaquePixelsCount > 0/* && currentIteration < 4*/)
	{
		printf("Iteration %d:\n", currentIteration);
		dim3 scoresCountingBlock(BLOCK_SIZE);
		dim3 scoresCountingGrid(SpritesCount, 1, SizingsCount); //Сайзингов будет меньше, чем спрайтов, так что сайзинги записываем в z
		//printf("%d,%d,%d\n", BLOCK_SIZE, SpritesCount, SizingsCount);
		countScores << <scoresCountingGrid, scoresCountingBlock >> > (rgbaData, voids, rgbaFlags, workingOffsets, scoresResults, indeciesInfo);
		cudaError_t scoreCountingError = cudaPeekAtLastError();
		if (scoreCountingError != cudaSuccess)
		{
			printf("scoreCountingError = %d, %s\n", scoreCountingError, cudaGetErrorString(scoreCountingError));
			return;
		}
		//gpuErrchk(cudaPeekAtLastError());
		cudaDeviceSynchronize();
		//return;

		/*if (currentIteration == 94)
		{
			int blocksCount = ceilToInt(workingScoresLength, BLOCK_SIZE);
			for (size_t i = 0; i < BLOCK_SIZE * blocksCount; i++)
			{
				int apodko = scoresResults[i];
				if (apodko >= 1)
				{
					printf("score %d: %d. Sprite index = %d, sizing = %d, test = %d.", i, apodko, indeciesInfo[i], indeciesInfo[OptimizedScoresCount + i], 111222);
					printf(" The sizing of %d is (%d, %d)\n", indeciesInfo[OptimizedScoresCount + i], SizingWidths[indeciesInfo[OptimizedScoresCount + i]], SizingHeights[indeciesInfo[OptimizedScoresCount + i]]);
				}
			}
		}*/

		dim3 bestScoreFindingBlock(BLOCK_SIZE);
		int currentBestScoresLength = workingScoresLength;
		int depth = 0;
		while (true)
		{
			int gridLength = ceilToInt(currentBestScoresLength, BLOCK_SIZE);
			dim3 bestScoreFindingGrid(gridLength);
			//printf("ASJISjdkskjmalkdjasid\n");
			findTheBestScore << <bestScoreFindingGrid, bestScoreFindingBlock >> > (scoresResults, indecies, indeciesInfo, depth, currentBestScoresLength, workingScoresLength);
			cudaDeviceSynchronize();
			if (currentBestScoresLength <= WARP_SIZE) //Если на входе к findTheBestScore было 32 значения или меньше, значит на выходе осталось 1 значение - победитель.
				break;
			currentBestScoresLength = gridLength * WARP_SIZE;
			depth++;
		}

		printf("AAAaaaaaaaaaannd the WINNER is %d with the ASTONISHING score of %d!!!!!!!!!!!! !!! !! !!!!! ! !!11   ... . .  .\n", indecies[0], scoresResults[0]);
		printf("Aaaaannd the sprite id of the winner is %d. And the sizing is %d.\n", indeciesInfo[0], indeciesInfo[OptimizedScoresCount]);
		int workingOffsetOfTheWinner = workingOffsets[indeciesInfo[0] * SizingsCount + indeciesInfo[OptimizedScoresCount]];
		short sizingWidth = SizingWidths[indeciesInfo[OptimizedScoresCount]];
		short sizingHeight = SizingHeights[indeciesInfo[OptimizedScoresCount]];
		int workingHeight = SpriteHeights[indeciesInfo[0]] - sizingHeight + 1;
		int indexOfPixelOfTheWinner = indecies[0] - workingOffsetOfTheWinner;
		short winnerAreaX = indexOfPixelOfTheWinner / workingHeight;
		short winnerAreaY = indexOfPixelOfTheWinner % workingHeight;
		printf("Winner area: Sprite %d, Sizing %d, x %d, y %d, width %d, height %d\n", indeciesInfo[0], indeciesInfo[OptimizedScoresCount], winnerAreaX, winnerAreaY, sizingWidth, sizingHeight);

		memcpy(atlas + currentIteration * (sizeof(unsigned int) + sizeof(unsigned short) * 4), &indeciesInfo[0], sizeof(unsigned int));
		memcpy(atlas + currentIteration * (sizeof(unsigned int) + sizeof(unsigned short) * 4) + sizeof(unsigned int), &winnerAreaX, sizeof(unsigned short));
		memcpy(atlas + currentIteration * (sizeof(unsigned int) + sizeof(unsigned short) * 4) + sizeof(unsigned int) + sizeof(unsigned short), &winnerAreaY, sizeof(unsigned short));
		memcpy(atlas + currentIteration * (sizeof(unsigned int) + sizeof(unsigned short) * 4) + sizeof(unsigned int) + sizeof(unsigned short) * 2, &sizingWidth, sizeof(unsigned short));
		memcpy(atlas + currentIteration * (sizeof(unsigned int) + sizeof(unsigned short) * 4) + sizeof(unsigned int) + sizeof(unsigned short) * 3, &sizingHeight, sizeof(unsigned short));

		short winnersOpaquePixelsCount = 0;
		for (size_t x = 0; x < sizingWidth; x++)
		{
			for (size_t y = 0; y < sizingHeight; y++)
			{
				int index = (winnerAreaX + x) * SpriteHeights[indeciesInfo[0]] + winnerAreaY + y;
				if (rgbaData[ByteLineLength * 3 + SpriteByteOffsets[indeciesInfo[0]] + index] != 0)
					winnersOpaquePixelsCount++;
			}
		}

		printf("winnersOpaquePixelsCount = %d\n", winnersOpaquePixelsCount);

		dim3 bestAreaStrippingBlock(1); //Мда, а что поделать....
		dim3 bestAreaStrippingGrid(SpritesCount); //Нам здесь не нужно учитывать сайзинги. А раз так, кол-во блоков будет равно просто кол-ву спрайтов.
		stripTheWinnerAreaFromData << <bestAreaStrippingGrid, bestAreaStrippingBlock >> > (rgbaData, voids, rgbaFlags, indeciesInfo[0], indeciesInfo[OptimizedScoresCount], winnerAreaX, winnerAreaY, sizingWidth, sizingHeight, currentIteration, offsets, spritesCountSizedArray);
		cudaDeviceSynchronize();
		unsigned int strippedAreasCount = 0;
		for (size_t i = 0; i < SpritesCount; i++)
			strippedAreasCount += spritesCountSizedArray[i];

		/*if (currentIteration == 94)
			printf("erasing the last area: %d, %d, %d, %d, %d. Before that strippedAreasCount = %d, test = %d\n", indeciesInfo[0], winnerAreaX, winnerAreaY, sizingWidth, sizingHeight, strippedAreasCount, 123124);*/
			//printf("BitLineLength = %d\n", (int)BitLineLength);
		erase(rgbaData, voids, rgbaFlags, indeciesInfo[0], indeciesInfo[OptimizedScoresCount], winnerAreaX, winnerAreaY, sizingWidth, sizingHeight, true); //После того, как стерли все совпадения с победителем, стираем и самого победителя
		offsets[SpriteByteOffsets[indeciesInfo[0]] + winnerAreaX * SpriteHeights[indeciesInfo[0]] + winnerAreaY] = currentIteration + 1;
		printf("strippedAreasCount = %d\n", (strippedAreasCount + 1) * winnersOpaquePixelsCount); //+1, потому что победителя мы стираем отдельно и он тоже считается


		memset(scoresResults, 0, optimizedWorkingScoresLength * sizeof(int));

		opaquePixelsCount -= (strippedAreasCount + 1) * winnersOpaquePixelsCount;
		printf("Opaque Pixels Left: %d\n", opaquePixelsCount);
		currentIteration++;
		/*if (opaquePixelsCount <= 0)
			break;*/

			//break;
			/*if (currentIteration > 19)
				break;*/
	}
	printf("The End! opaquePixelsCount = %d.\n", opaquePixelsCount);

	atlasLength[0] = currentIteration;
}

int main()
{
	cudaDeviceReset();

	//string path = "P:\\U\\Some2DGame\\Cuda\\info\\new-data.bytes";
	//string fileName = "+Ki2mqq6D3CLZJcSc1ukx6aKwsQ=";
	string fileName = "3L1lKIrjiyQGNUbZLCjrm3IBMjQ=";
	string path = "P:\\U\\Some2DGame\\Assets\\SpritesheetOptimizer\\SomewhatCleanVersion\\DB\\Exported\\" + fileName + ".bytes";
	tuple<char*, int> blobTuple = file_reader::readFile(path);
	char* blob = get<0>(blobTuple);
	int blobLength = get<1>(blobTuple);

	//blob состоит из мета-инфы, которую мы не используем в рассчетах, и основной инфы. Мета - 4 байта длина и собственно данные.
	int metaLength = bit_converter::GetInt(blob, 0);
	int combinedDataOffset = metaLength + sizeof(int); //указатель на начало массива основных данных

	short spritesCount = bit_converter::GetShort(blob, combinedDataOffset + RESERVED_DATA_LENGHT); // первые 2 байта основных данных зарезервированы, вторые - кол-во спрайтов.
	cudaMemcpyToSymbol(SpritesCount, &spritesCount, sizeof(short)); //Сразу записываем их в константы устройства
	short sizingsCount = bit_converter::GetShort(blob, combinedDataOffset + RESERVED_DATA_LENGHT + sizeof(short)); //третьи 2 байта - кол-во сайзингов
	cudaMemcpyToSymbol(SizingsCount, &sizingsCount, sizeof(short)); //Тоже записываем сразу туда.

	//Определяем массивы и длины данных сайзингов и регистра

	//Сначала сайзинги...
	char* sizingsBlob = blob + combinedDataOffset + RESERVED_DATA_LENGHT + sizeof(short) * 2;
	int sizingsBlobLenght = sizingsCount * SIZING_STRUCTURE_LENGTH; //Сайзинги состоят из 2 шортов - х и у
	//Записываем сайзинги на девайс. Они там идут последовательно, сначала иксы потом игрики
	int sizingsLineLength = sizeof(short) * sizingsCount;
	short* sizingWidths = (short*)sizingsBlob;
	short* sizingHeights = (short*)(sizingsBlob + sizingsLineLength);
	cudaMemcpyToSymbol(SizingWidths, sizingWidths, sizingsLineLength);
	cudaMemcpyToSymbol(SizingHeights, sizingHeights, sizingsLineLength);

	/*for (size_t i = 0; i < sizingsCount; i++)
		printf("Sizing #%d: %d,%d\n", i, sizingWidths[i], sizingHeights[i]);
	return;*/

	char* registryBlob = sizingsBlob + sizingsBlobLenght;
	int registryBlobLength = spritesCount * REGISTRY_STRUCTURE_LENGTH; //регистр на данный момент состоит из 2 шортов и 2 интов, длина структуры задается через REGISTRY_STRUCTURE_LENGTH
	//Записываем регистр на девайс. Они там идут последовательно, сначала байтовые оффсеты потом битовые, потом иксы, потом игрики
	//int registryLineCount = spritesCount * sizingsCount;
	int* spriteByteOffsets = (int*)registryBlob;
	int* spriteBitOffsets = (int*)(registryBlob + spritesCount * sizeof(int));
	short* spriteWidths = (short*)(registryBlob + spritesCount * sizeof(int) * 2);
	short* spriteHeights = (short*)(registryBlob + spritesCount * (sizeof(int) * 2 + sizeof(short)));
	cudaMemcpyToSymbol(SpriteByteOffsets, spriteByteOffsets, spritesCount * sizeof(int));
	cudaMemcpyToSymbol(SpriteBitOffsets, spriteBitOffsets, spritesCount * sizeof(int));
	cudaMemcpyToSymbol(SpriteWidths, spriteWidths, spritesCount * sizeof(short));
	cudaMemcpyToSymbol(SpriteHeights, spriteHeights, spritesCount * sizeof(short));

	/*for (size_t i = 0; i < spritesCount; i++)
	{
		printf("SpriteHeights[%d] = %d. SpriteWidths[%d] = %d\n", i, spriteHeights[i], i, spriteWidths[i]);
	}

	return;*/

	//Дальше идет длина 1 канала цвета
	int byteLineLength = bit_converter::GetInt(registryBlob + registryBlobLength, 0);
	cudaMemcpyToSymbol(ByteLineLength, &byteLineLength, sizeof(int)); //Сразу записываем ее в константы

	//Дальше идут данные. А зная длину 1 канала цвета, мы можем легко посчитать общую длину массива цветов
	char* rgbaBlob = registryBlob + registryBlobLength + sizeof(int);
	int rgbaBlobLength = byteLineLength * DATA_STRUCTURE_LENGTH; //Длина структуры основных данных у нас 4 - по 1 байту на канал.
	//Сразу записываем их в глобальную память
	char* deviceRgbaDataPtr;
	cudaMalloc((void**)&deviceRgbaDataPtr, rgbaBlobLength);
	cudaMemcpy(deviceRgbaDataPtr, rgbaBlob, rgbaBlobLength, cudaMemcpyHostToDevice);

	/*
		Это были основные данные. Дальше идут вспомогательные.
	*/


	//Следующими за данными о цвете идут оффсеты карт пустот
	int voidMapsCount = spritesCount * sizingsCount; //Карта пустот есть отдельно для каждого спрайта каждого сайзинга
	int* voidMapsOffsets = (int*)(rgbaBlob + rgbaBlobLength);
	int voidMapsOffsetsLength = voidMapsCount * sizeof(int);
	cudaMemcpyToSymbol(VoidOffsets, voidMapsOffsets, voidMapsOffsetsLength); //Пишем ее в константы

	//Потом длина уже непосредственно карт и за ней - сами данные карты
	int voidsBlobLength = bit_converter::GetInt((char*)(voidMapsOffsets + voidMapsCount), 0);
	char* voidsBlob = (char*)(voidMapsOffsets + voidMapsCount) + sizeof(int);
	//Пишем эти данные в глобал мемори
	char* deviceVoidsPtr;
	cudaMalloc((void**)&deviceVoidsPtr, voidsBlobLength);
	cudaMemcpy(deviceVoidsPtr, voidsBlob, voidsBlobLength, cudaMemcpyHostToDevice);

	//Дальше длина канала основных данных в битах
	int bitLineLength = bit_converter::GetInt(voidsBlob + voidsBlobLength, 0);
	cudaMemcpyToSymbol(BitLineLength, &bitLineLength, sizeof(int)); // Сразу записываем ее
	char* rgbaFlags = voidsBlob + voidsBlobLength + sizeof(int);
	int rgbaFlagsLength = bitLineLength * DATA_STRUCTURE_LENGTH;
	//Пишем их тоже в глобальную
	char* deviceRgbaFlagsPtr;
	cudaMalloc((void**)&deviceRgbaFlagsPtr, rgbaFlagsLength);
	cudaMemcpy(deviceRgbaFlagsPtr, rgbaFlags, rgbaFlagsLength, cudaMemcpyHostToDevice);

	//Дальше у нас scoresCount и за ним - байтовые working-оффсеты
	unsigned int scoresCount = bit_converter::GetUnsignedInt(rgbaFlags + rgbaFlagsLength, 0);
	cudaMemcpyToSymbol(ScoresCount, &scoresCount, sizeof(unsigned int)); // Делаем это значение константой
	unsigned int* workingByteOffsets = (unsigned int*)(rgbaFlags + rgbaFlagsLength + sizeof(unsigned int));
	unsigned int workingByteOffsetsLength = spritesCount * sizingsCount * sizeof(unsigned int);
	/*unsigned int* deviceWorkingByteOffsetsPtr;
	cudaMalloc((void**)&deviceWorkingByteOffsetsPtr, workingByteOffsetsLength);
	cudaMemcpy(deviceWorkingByteOffsetsPtr, workingByteOffsets, workingByteOffsetsLength, cudaMemcpyHostToDevice);*/

	//После этого у нас там наш замечательный OpaquePixelsCount
	unsigned int opaquePixelsCount = bit_converter::GetUnsignedInt((char*)(workingByteOffsets + spritesCount * sizingsCount), 0);

	///*
	//	Ок, нам нужны области памяти для хранения промежуточных результатов. Первый промежуточный результат - это счет спрайто-размеро-спрайта. Второй - общий счет спрайто-размера. Первый получается довольно
	//	огромным. Допустим, у нас 3000 спрайтов 256х256, тогда размер структуры для первого промежуточного результата нужен будет такой: 256х256х3000х22х3000х4 байт, то есть... всего лишь 2 терабайта памяти.
	//	Прикольно. Ок. Я посчитал, если не брать в расчет первую промежуточную структуру, а сразу писать во вторую - максимальное кол-во спрайтов размера 256х256, которое мы сможем взять - 1733. Т.е. где-то
	//	113 мегапикселей за раз. Ну, это, конечно, не мало само по себе, но с другой - это всего лишь 7 4к-текстур. Конечно, можно будет как-то выкручиваться - свопом, уменьшением кол-ва сайзингов, но вообще
	//	в будущем, конечно, стоит придумать нормальное решение для этой проблемы. Может обсчитывать в несколько проходов с выгрузкой промежуточных результатов в оперативку. В принципе не так сложно должно
	//	быть сделать. А на первое время, я думаю, такого кол-ва хватит. А стратегию подсчета конечно же надо будет поменять на подсчет сразу в итоговый результат. Т.е. пропускаем первую промежуточную стадию.
	//*/

	////Размерность матриц результатов у нас не совпадает с размерностью спрайтов из-за сайзингов.
	////Еще нам нужны байтовые оффсеты рабочих областей спрайтов, раз мы хотим экономить место. Битовые войд-оффсеты не подходят, т.к. там округляются значения до кратных 8.
	////В будущем вот это вот всё надо будет перенести на клиента.
	//unsigned int legacyScoresCount = 0;
	//unsigned int* workingSpriteOffsets = (unsigned int*)malloc(sizingsCount * spritesCount * sizeof(int));
	//unsigned int currentOffset = 0;
	//for (size_t i = 0; i < spritesCount; i++)
	//{
	//	int spriteWidth = spriteWidths[i];
	//	int spriteHeight = spriteHeights[i];
	//	for (size_t j = 0; j < sizingsCount; j++)
	//	{
	//		short sizingWidth = sizingWidths[j];
	//		short sizingHeight = sizingHeights[j];

	//		unsigned int currentWorkingSpriteLength = (spriteWidth - sizingWidth) * (spriteHeight - sizingHeight);
	//		legacyScoresCount += currentWorkingSpriteLength;
	//		//std::cout << "spriteWidth = " << spriteWidth << " sizingWidth = " << sizingWidth << " spriteHeight = " << spriteHeight << " sizingHeight = " << sizingHeight << "\n";
	//		workingSpriteOffsets[i * sizingsCount + j] = currentOffset;
	//		currentOffset += currentWorkingSpriteLength;
	//	}
	//}

	//printf("scoresCount = %d %d, workingSpriteOffsets[15] = %d %d, opaquePixelsCount = %d\n", legacyScoresCount, scoresCount, workingSpriteOffsets[15], workingByteOffsets[15], opaquePixelsCount);


	char* deviceScoresPtr;
	char* deviceIndeciesPtr;
	int* deviceIndeciesInfoPtr;
	char* deviceAtlasPtr;
	int atlasSize = byteLineLength * sizeof(int) * 3;
	char* deviceOffsetsPtr;
	int offsetsSize = byteLineLength * sizeof(int);
	char* deviceSpritesCountSizedArrayPtr;
	int optimizedScoresCount = hostCeilToInt(scoresCount, BLOCK_SIZE) * BLOCK_SIZE; //Делаем кол-во результатов кратным BLOCK_SIZE, чтобы потом было легче высчитывать победителя
	cudaMemcpyToSymbol(OptimizedScoresCount, &optimizedScoresCount, sizeof(int)); // Сразу записываем его
	cudaMalloc((void**)&deviceScoresPtr, optimizedScoresCount * sizeof(int));
	cudaMalloc((void**)&deviceIndeciesPtr, optimizedScoresCount * sizeof(int));
	cudaMalloc((void**)&deviceIndeciesInfoPtr, optimizedScoresCount * INDECIES_INFO_LENGHT); //int - для индекса спрайта, 2 short - для координат, 1 byte - для индекса области
	cudaMalloc((void**)&deviceAtlasPtr, atlasSize);
	cudaMalloc((void**)&deviceOffsetsPtr, offsetsSize);
	cudaMalloc((void**)&deviceSpritesCountSizedArrayPtr, spritesCount * sizeof(unsigned int));
	cudaMemset(deviceScoresPtr, 0, optimizedScoresCount * sizeof(int));
	cudaMemset(deviceAtlasPtr, 0, atlasSize);
	cudaMemset(deviceOffsetsPtr, 0, offsetsSize);
	unsigned int* deviceWorkingSpriteOffsetsPtr;
	cudaMalloc((void**)&deviceWorkingSpriteOffsetsPtr, sizingsCount * spritesCount * sizeof(unsigned int));
	cudaMemcpy(deviceWorkingSpriteOffsetsPtr, workingByteOffsets, sizingsCount * spritesCount * sizeof(unsigned int), cudaMemcpyHostToDevice);

	unsigned int* atlasLengthDevice;
	cudaMalloc((void**)&atlasLengthDevice, sizeof(unsigned int));

	//dim3 block(BLOCK_SIZE);
	//dim3 grid(spritesCount, 1, sizingsCount); //Сайзингов будет меньше, чем спрайтов, так что сайзинги записываем в z
	//mainKernel << <grid, block >> > ((unsigned char*)deviceRgbaDataPtr, (unsigned char*)deviceVoidsPtr, (unsigned char*)deviceRgbaFlagsPtr, deviceWorkingSpriteOffsetsPtr, (unsigned int*)deviceResultsPtr);
	mainKernel << <1, 1 >> > (opaquePixelsCount, (unsigned char*)deviceRgbaDataPtr, (unsigned char*)deviceVoidsPtr, (unsigned char*)deviceRgbaFlagsPtr, deviceWorkingSpriteOffsetsPtr, (int*)deviceScoresPtr, (unsigned int*)deviceIndeciesPtr, (unsigned int*)deviceIndeciesInfoPtr, scoresCount, optimizedScoresCount, deviceAtlasPtr, (unsigned int*)deviceOffsetsPtr, (unsigned int*)deviceSpritesCountSizedArrayPtr, atlasLengthDevice);
	gpuErrchk(cudaPeekAtLastError());
	cudaDeviceSynchronize();
	gpuErrchk(cudaPeekAtLastError());

	cudaError_t code = cudaGetLastError();
	printf("code = %d\n", code);
	if (code != cudaSuccess)
	{
		printf("Starting post gpu processing...\n");
		const char* errorMessage = cudaGetErrorString(code);
		printf("CUDA error returned from Error code: %d (%s)\n", code, errorMessage);
	}


	/*char* atlas = (char*)malloc(atlasSize);
	char* offsets = (char*)malloc(offsetsSize);
	cudaMemcpy(atlas, deviceAtlasPtr, atlasSize, cudaMemcpyDeviceToHost);
	cudaMemcpy(offsets, deviceOffsetsPtr, offsetsSize, cudaMemcpyDeviceToHost);
	unsigned int* altasLength;
	cudaMemcpy(altasLength, atlasLengthDevice, sizeof(unsigned int), cudaMemcpyDeviceToHost);*/

	unsigned int* altasLength = (unsigned int*)malloc(sizeof(unsigned int));
	cudaMemcpy(altasLength, atlasLengthDevice, sizeof(unsigned int), cudaMemcpyDeviceToHost);

	char* atlasPtr = (char*)malloc(atlasSize);
	cudaMemcpy(atlasPtr, deviceAtlasPtr, atlasSize, cudaMemcpyDeviceToHost);
	unsigned int* offsetsPtr = (unsigned int*)malloc(offsetsSize);
	cudaMemcpy(offsetsPtr, deviceOffsetsPtr, offsetsSize, cudaMemcpyDeviceToHost);


	cudaFree(deviceRgbaDataPtr);
	cudaFree(deviceVoidsPtr);
	cudaFree(deviceRgbaFlagsPtr);
	//cudaFree(deviceWorkingByteOffsetsPtr);

	cudaFree(deviceScoresPtr);
	cudaFree(deviceIndeciesPtr);
	cudaFree(deviceIndeciesInfoPtr);
	cudaFree(deviceAtlasPtr);
	cudaFree(deviceOffsetsPtr);
	cudaFree(deviceSpritesCountSizedArrayPtr);

	cudaFree(deviceWorkingSpriteOffsetsPtr);
	cudaFree(atlasLengthDevice);
	printf("7\n");


	printf("atlas length is %d\n", altasLength[0]);

	std::tuple<char*, int> bufferAndLength = format_packer::pack(altasLength[0], atlasPtr, offsetsPtr, spritesCount, spriteWidths, spriteHeights, blob, metaLength + sizeof(int));

	char* buffer = get<0>(bufferAndLength);
	int bufferLength = get<1>(bufferAndLength);

	std::ofstream ofile(fileName + ".bytes", std::ios::binary);
	ofile.write(buffer, bufferLength);

	printf("bufferLength = %d\n", bufferLength);

	//printf("atlas length is %d\n", altasLength[0]);


	//free(buffer);
	printf("1\n");

	free(offsetsPtr);
	printf("2\n");
	free(atlasPtr);
	printf("3\n");
	free(altasLength);
	printf("4\n");
	free(blob);

	printf("8\n");

	cudaDeviceReset();
	printf("9\n");

	return 0;
}
